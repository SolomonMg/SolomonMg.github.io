
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Working on AI, politics, and policy with CSMaP at NYU. Full bio below.\nCurrent Projects\nPropaganda \u0026amp; Politics in Generative AI Understanding the influence of political messaging on model output across langauges using evidence from training data, audits, and real-world usage.\nNew methods with LLMs Quantifying the spread of ideas across langauges using LLMs. Creating new measures of ideology using forced-choice games played by people and LLMs.\nPolitics and Short Form Video Characterizing political content on TikTok. Investigating content moderation for Pro- \u0026amp; Anti- China videos on TikTok and YouTube. Analysis of hate speech on TikTok. A TikTok field experiment.\n","date":1549324800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"2019-02-05T00:00:00Z","relpermalink":"","section":"authors","summary":"Working on AI, politics, and policy with CSMaP at NYU. Full bio below.\nCurrent Projects\nPropaganda \u0026 Politics in Generative AI Understanding the influence of political messaging on model output across langauges using evidence from training data, audits, and real-world usage.\n","tags":null,"title":"Sol Messing","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://solmessing.netlify.app/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Hannah Waight","Solomon Messing","Anton Shirikov","Margaret E. Roberts","Jonathan Nagler","Jason Greenfield","Megan A. Brown","Kevin Aslett","Joshua A. Tucker"],"categories":null,"content":" Replication materials ","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"6292f5e1d00b58ec09caa2863f045e5a","permalink":"https://solmessing.netlify.app/publication/waightmessing2025/","publishdate":"2025-08-12T00:00:00Z","relpermalink":"/publication/waightmessing2025/","section":"publication","summary":"How can one understand the spread of ideas across text data? This is a key measurement problem in sociological inquiry, from the study of how interest groups shape media discourse, to the spread of policy across institutions, to the diffusion of organizational structures and institution themselves. To study how ideas and narratives diffuse across text, we must first develop a method to identify whether texts share the same information and narratives, rather than the same broad themes or exact features. We propose a novel approach to measure this quantity of interest, which we call “narrative similarity,” by using large language models to distill texts to their core ideas and then compare the similarity of claims rather than of words, phrases, or sentences. The result is an estimand much closer to narrative similarity than what is possible with past relevant alternatives, including exact text reuse, which returns lexically similar documents; topic modeling, which returns topically similar documents; or an array of alternative approaches. We devise an approach to providing out-of-sample measures of performance (precision, recall, F1) and show that our approach outperforms relevant alternatives by a large margin. We apply our approach to an important case study: The spread of Russian claims about the development of a Ukrainian bioweapons program in U.S. mainstream and fringe news websites. While we focus on news in this application, our approach can be applied more broadly to the study of propaganda, misinformation, diffusion of policy and cultural objects, among other topics.","tags":null,"title":"Quantifying Narrative Similarity Across Languages","type":"publication"},{"authors":["Sol Messing"],"categories":[],"content":"Early projections for 2024 based on previous Presidential and House returns slighly favor Republicans. These projections are completely unrelated to Biden’s recent polling numbers.\nHere’s the story behind this approach: In early 2020, I ran battleground state election forecasts for Acronym. The results suggested Georgia would be extremely competitive—and Acronym spent more $ there than many other non-profit actors. After the election, we could see that those projections had much lower forecasting error than polling data https://solomonmg.github.io/post/what-the-polls-got-wrong-in-2020/.\nBecause this approach does not use polling data, it’s not suspetible to any of the potential problems with polls I talk about in that post: undecided voters breaking late, low education non-response, bad likely voter modeling, partisan non-response, shy Trumpers, etc.\nThe core idea behind this approach is a fact not emphasized enough in most stats/ML courses: if you’re going to try to predict something, it’s very hard to do better than using the same variable at t - 1 if you can. And we can. This approach goes one step further and looks at the direction that variable has been moving and assume that things are likely to keep moving in that same direction.\nWhat that means for presidential election forecasts: for each state, estimate the “swing” from 2016 to 2020 for president and 2018-2022 for the U.S. house; then simply add that to 2020 presidential returns. Then those estimates of state-level swing are regularized—mathematically ``nudged’’ toward national trends, which you’ll like if you believe “uniform swing” is particularly important. The projected state-level swing is weighted 60-40 toward presidential results.\nHere’s a cleaner plot showing the actual forecast values in potential 2024 battleground states:\nA simple forecast for 2024 battleground states. Hat tip to Tom Cunningham who suggested this plot design. I should now point to a link to the data and code: https://github.com/SolomonMg/election_projection_regularized_swing, and thank the MIT Election Data + Science Lab for curating these data.\nElectoral Math: I’m going to rely on www.270towin.com to translate these projections into an electoral map. A better way to do this might be to come up with conservative estimates of error and simulate a few thousand elections, but I’m not estimating an extremely rigorous Bayesian model nor including enough extant data to really justify a FiveThirtyEight style forecast.\nIf you call anything lower than a 3 point margin either way a “tossup,” here’s what the electoral map looks like:\nElecotral map for 2024, lower than a 3% margin is a tossup. Created https://www.270towin.com/maps/WWE2B. That looks OK for Biden, but if you really trust this approach, you might want to say anything lower than 2% is a tossup. Then the electoral math looks very bad for Biden:\nElecotral map for 2024, lower than a 2% margin is a tossup. Created https://www.270towin.com/maps/WWExg. Observation: Polarization and Accuracy These projections essentially assume party identification, demographic trends, and voting behavior will mostly continue in the same general direction as in the past. They should have a lot of appeal if you think polarization means most people have already made up their minds about who to vote for for President, that Presidential campaign effects are relatively small (in equilibrium at least), and/or that “demographics are destiny.” What’s more, the results are regularized toward national trends, which you’ll like if you believe that local politics has been ``nationalized,’’ as Dan Hopkins argues and thus that “uniform swing” in the electorate is an increasingly important factor explaining state-level election results—despite that Florida bucked the national trend in 2020.\nIn fact, over time, as polarization seems to worsen, this approach improves in accuracy:\nBacktested forecasts improve in accuracy over time, and 2020 was far easier to predict than past elections. However, these projections do not account for events since 2022. Older voters pass away and younger voters become eligible to vote changing the makeup of the electorate. Public opinion/sentiment may change related to economic conditions (inflation/income/unemployment/etc), policy developments e.g., related to abortion, international affairs like the Gaza conflict, or candidate-attributes like Biden’s age or Trumps legal troubles.\nObservation: Patterns in U.S. Elections These projections also do not explicitly model well-known voting patterns, instead relying on change from one cycle to another to get reasonable estimates. The most notable trend is that the president’s party almost always tends to lose seats in the house in midterm elections. https://www.jstor.org/stable/2130810 https://fivethirtyeight.com/features/why-the-presidents-party-almost-always-has-a-bad-midterm/\nBecause the model only looks at the state-level the difference between the last two midterm cycles, these …","date":1704931200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704931200,"objectID":"a55f0372b4733a5f6a46df8ad7524dfb","permalink":"https://solmessing.netlify.app/post/election_projection_regularized_swing/","publishdate":"2024-01-11T00:00:00Z","relpermalink":"/post/election_projection_regularized_swing/","section":"post","summary":"Early projections for 2024 based on previous Presidential and House returns slighly favor Republicans. These projections are completely unrelated to Biden’s recent polling numbers.\n","tags":[],"title":"An Early Election 2024 Forecast","type":"post"},{"authors":["Sol Messing"],"categories":[],"content":"TLDR: [UPDATED SEPT 30] Yesterday, Science published a letter I wrote arguing that there is little evidence of algorithmic bias in Facebook’s feed ranking system that would serve to increase ideological segregation, also known as the “Filter Bubble” hypothesis. This contradicts claims in González-Bailón et al 2023 that Newsfeed ranking increases ideological segregation. This claim was the main piece of evidence in the Science Special Issue on Meta that might support the controversial cover that suggested that Meta’s algorithms are “Wired to Split.” The issue is that while domain-level analysis suggests feed-ranking increases ideological segregation, URL-level analysis shows no difference in ideological segregation before and after feed-ranking. And we should strongly prefer their URL-level analysis. Domain-level analysis effectively mislabels highly partisan content as “moderate/mixed,” especially on websites like YouTube, Reddit, and Twitter (aggregation bias/ecological fallacy). Interestingly, the authors seem to agree—the discussion section points out problems with domain-level analysis. Another Science paper from the same issue, Guess et al 2023 shows (in the SM) that Newsfeed ranking actually decreases exposure to political content from like-minded sources compared with reverse-chronological feedranking. The evidence in the 4 recent papers is not consistent with a meaningful Filter Bubble effect in 2020; nor does it support the notion that Meta’s algorithms are “Wired to Split.” Furthermore, domain-level aggregation bias is a big issue in a great deal of past research on ideological segregation, because domain-level analysis understates media polarization. Because González-Bailón et al 2023 gives both URL- and domain-level estimates, we can see the magnitude of aggregation bias. It’s huge. I make a number of other observations about what we know about whether social media is polarizing and discuss implications for the controversial Science cover and Meta’s flawed claims that this research is exculpatory. Intro/ICYMI Click to expand Last week saw the release of a series of excellent papers in Science. I was particularly interested in González-Bailón et al 2023, which measures “ideological segregation.” This concept is based on Matt Gentzkow and Jesse Shapiro’s 2011 work. As they note, “The index ranges from 0 (all conservative and liberal visits are to the same outlet) to 1 (conservatives only visit 100% conservative outlets and liberals only visit 100% liberal outlets).”\nThis paper also replicates and extends my own work with Eytan Bakshy and Lada Adamic, also published in Science in 2015.\nTo be clear González-Bailón et al 2023 goes a lot further, examining how these factors vary over-time, investigating clusters of isolated partisan media organizations, and patterns in the consumption of misinformation. They find (1) ideological segregation is high; (2) ideological segregation “increases after algorithmic curation” consistent with the “Filter Bubble” hypothesis; (3) there is a substantial right wing “echo chamber” in which conservatives are essentially siloed from the rest of the site (4) where misinformation thrives.\nI’ve had many years to think about issues related to these questions, after working with similar data from 2012 in my dissertation, and co-authoring a Science paper while working at Facebook using 2014 data. I also saw the design (but not results) presented at the 2023 SSRC Workshop on the Economics of Social Media, though I did not notice these issues until I saw the final paper.\nI put together these thoughts after discussion and feedback from Dean Eckles and Tom Cunningham, former colleagues at Stanford, Facebook, and Twitter.\nA Brief History of Echo Chambers, Filter Bubbles, and Selective Exposure Click to expand The conventional academic wisdom when I started my PhD was that we shouldn’t expect to see much in the way of media effects (Klapper 1960) because people tended to “select into” content that reinforced their views (Sears and Freedman 1967).\nIn 2007, Cass Sunstein wrote “Republic.com 2.0”, which warned that the internet could allow us to even more easily isolate ourselves into “information cocoons” and “echo chambers.” Technology allows us to “filter” exactly what we want to see, and design our own programming. Cass also suggested this could lead to polarization.\nIn 2009-2010, Sean Westwood and I ran a series of studies suggesting that popularity and social cues in news aggregators and social media websites might be a way out of selective news consumption—we might be more exposed to cross-cutting views on platforms that feature a social component, and furthermore, this social component seemed to be more important that media “source” label. That was great in the abstract, but what happens on actual websites that people use?\nThe extent to which widely used social media platforms might allow us to exit “echo chambers” depended on the extent of cross-partisan friendships and …","date":1690934400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690934400,"objectID":"9d425fa8df98c1daeacd89a289b8834f","permalink":"https://solmessing.netlify.app/post/thoughts-on-election-2020/","publishdate":"2023-08-02T00:00:00Z","relpermalink":"/post/thoughts-on-election-2020/","section":"post","summary":"Analysis of recent Science papers shows little evidence that Facebook's feed ranking increases ideological segregation or creates a meaningful 'Filter Bubble' effect.","tags":[],"title":"Disaggregating 'Ideological Segregation'","type":"post"},{"authors":["Sol Messing"],"categories":[],"content":"TL/DR Summary\nBlueSky has a chance to dethrone twitter right now, but that path is narrow. Its exclusive invite only model means its user base is now small, elite, and homogenous with few bad actors. Almost everyone likes it. But the real test will be when it opens to the public. It is designed for true account portability and in theory should prevent a single company from owning the entire network as it scales up. However, it’s unclear if an ecosystem of small companies can do the job of content moderation in the same ways that centralized social networks do. The same is true of running modern feed-ranking and follow-recommendation systems. There will be growing pressure to make money using ads to cover costs as the network scales up, which will incentivize centralizing key data and resources, undermining the original model. Future possibilities include: (1) BlueSky remains de-facto centralized, “in beta” until it can get composable moderation right, which turns out to be the foreseeable future; (2) big players (Google, Facebook) join the party and dominate the ecosystem; (3) small, unmoderated, ad-free apps proliferate and the network becomes overrun with spam, NSFW, hate, scams and gifts that come with a lack of moderation. Pretty much everyone at Twitter—and especially Jack Dorsey—has long known that BlueSky could replace Twitter. When I joined Twitter in 2021, I soon learned our CEO was terribly unpopular internally, sporting a job approval rating under 40 percent, by far the lowest of any executive at the company.\nIn fact, Jack was obsessed with decentralization, he seemed convinced that it was a mistake to have Twitter organized as a corporation, and he would rant about this on company-wide calls, which he seemed to be taking from caves in South Asia. This is when everyone else at the company was desperately trying to increase revenues to save the company from implosion.\nThis photo of Jack Dorsey captures his general aspect on many all-hands calls. Enter BlueSky, which would decentralize Twitter. Jack launched the initiative in 2019, and his plan was to migrate Twitter to this new protocol. It puts user data including posts and follow lists on open, public portable data servers (PDSs) that mean true account portability. Any business or organization could index the those servers, or what I will call the “BlueSkyVerse” (technically the AT Protocol), rank posts, and create a front end interface.\nThe BlueSky App reads posts and the follow graph from Portable Data Servers, centralizing them in an index, ranking, and dislaying them for users. But wait a minute! Remember during Elon Musk’s acquisition how everyone said that the value of twitter isn’t the tech, but rather the network of creators and the communities that exist there? If you decouple that network from the platform you give up your most valuable asset—Google, Meta, others can index the network, develop a user interface, create some algorithms, show ads, and eat your lunch.\nAnd yet, Jack was about to do just that, filling Twitter’s moat by turning its most valuable asset into a protocol. Of course, this did not go over well with employees who weren’t independently wealthy, nor the board, who eventually pushed him out.\nBlueSky nicely captures the essence of Jack’s reign as half-time CEO: how little he cared about Twitter as a business and how much he cared about Twitter as an ecosystem.\nBut back to the question everyone cares about right now: will this new system lead to a better social network, or set of networks? Is this finally the Twitter alternative we’re looking for?\nMake no mistake about it—BlueSky was designed by Twitter to replace Twitter. This makes it very different from the other new social media protocols, apps, etc. that we’ve seen come on the scene of late. As John Gruber put it, “If you hated Twitter, you’ll like Mastodon. If you liked Twitter, you’ll love BlueSky.”\nSo it’s a contender, despite how hard it is to start a social network from scratch. And don’t get any funny ideas about a post-surveillance-capitalism social network—if BlueSky takes off, it will most likely devolve into a less-moderated, less-profitable version of Twitter, Inc (aka Twitter 1.0). It will indeed encourage competition for front-end interfaces to explore the BlueSkyVerse. But the biggest challenges that social networks have to face—content moderation, discoverability, and monetization—require big technical and infrastructural investments to do well. They may only be viable for well-capitalized companies that generate big profits.\nBut of course, I would be very nervous if I still worked at Twitter.\nWill it work?\nNow is a unique opportunity for a Twitter rival. Twitter CEO Elon Musk tends to say all manner of nutty things, he has decimated Twitter’s trust and safety org, and cut staffing by more than 80%. And the company slashed infrastructure budgets needed for automated content moderation—internal sources say the company has cut 3bn since peak spending …","date":1680480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680480000,"objectID":"dded5e31a826a0e934cde4d8f12bbf35","permalink":"https://solmessing.netlify.app/post/bluesky-quasi-decentralized-social-network/","publishdate":"2023-04-03T00:00:00Z","relpermalink":"/post/bluesky-quasi-decentralized-social-network/","section":"post","summary":"TL/DR Summary\nBlueSky has a chance to dethrone twitter right now, but that path is narrow. Its exclusive invite only model means its user base is now small, elite, and homogenous with few bad actors. Almost everyone likes it. But the real test will be when it opens to the public. It is designed for true account portability and in theory should prevent a single company from owning the entire network as it scales up. However, it’s unclear if an ecosystem of small companies can do the job of content moderation in the same ways that centralized social networks do. The same is true of running modern feed-ranking and follow-recommendation systems. There will be growing pressure to make money using ads to cover costs as the network scales up, which will incentivize centralizing key data and resources, undermining the original model. Future possibilities include: (1) BlueSky remains de-facto centralized, “in beta” until it can get composable moderation right, which turns out to be the foreseeable future; (2) big players (Google, Facebook) join the party and dominate the ecosystem; (3) small, unmoderated, ad-free apps proliferate and the network becomes overrun with spam, NSFW, hate, scams and gifts that come with a lack of moderation. Pretty much everyone at Twitter—and especially Jack Dorsey—has long known that BlueSky could replace Twitter. When I joined Twitter in 2021, I soon learned our CEO was terribly unpopular internally, sporting a job approval rating under 40 percent, by far the lowest of any executive at the company.\n","tags":[],"title":"On BlueSky","type":"post"},{"authors":["Sol Messing"],"categories":[],"content":"Last Friday (2023-03-31) Twitter released what it calls “the algorithm,” which appears to be a highly redacted, incomplete part of code that governs the “for you” home timeline ranking system. And I saw nothing to suggest the parts of the code they put in the GitHub repository wasn’t authentic.\nIt’s highly unusual for a tech company to open up a product at the core of its monetization strategy. The thinking is that the more engaging the content you show people right when they log in, the more likely they are to stick around. And the more you keep people logged in, the more they see ads. And the more data you can get to show them better ads!\nTransparency, or a distraction from closing the API?\nIs this a step forward for transparency as Musk and Twitter would claim? I am skeptical. You can’t learn much from this release in and of itself—you need the underlying model features, parameters, and data to really understand the algorithm. Those combine into a system that’s effectively different for everyone! So even if you had all that, you’d likely need to algorithmically audit the system to really get a handle on it.\nAnd Twitter made it prohibitively expensive for external researchers to get that data through its API with the recent price updates ($500k/yr). So at the same time twitter is releasing this code, it’s made it incredibly difficult for research to audit this code\nWhat’s in the code? Gossip and Rumors\nUkraine There were some initial reports that Twitter was downranking tweets about Ukraine. I looked at the code and can tell you those claims are wrong—twitter has an audio-only Clubhouse clone called Spaces and that code is for that product, not ordinary tweets on hometimeline. What’s more, this is likely a label related only to crisis misinformation, as per Twitter’s Crisis Misinformation Policy.\nUh, this code looks like it *only* relates to Twitter\u0026#39;s Spaces product. If so it is *not* used for down-ranking ordinary tweets in home timeline ranking. It\u0026#39;s called here with the other twitter Spaces spaces visibility models and labels: https://t.co/7n8Tl7WVlJ https://t.co/stSThUTvUe\n— Sol Messing (@SolomonMg) April 2, 2023 Musk Metrics One of the most interesting things we learned from the code is that Twitter created an entire suite of metrics about Elon Musk’s personal twitter experience. The code shows they fed those metrics to the experimentation platform (Duck Duck Goose, or DDG), which at least historically has been used to evaluate whether or not to ship products.\nTwitter’s algorithm specifically labels whether the Tweet author is Elon Musk\n“author_is_elon”\nbesides the Democrat, Republican and “Power User” labelshttps://t.co/fhpBjdfifX pic.twitter.com/orCPvfMTb9\n— Jane Manchun Wong (@wongmjane) March 31, 2023 This episode is consistent with reporting that engineers are very concerned about how any features they ship affect the CEOs personal experience on Twitter. And other reporting has suggested that there may have been a Musk centric boost feature that shipped, and you would want exactly this kind of instrumentation to understand how that worked in practice.\nRepublican, Democrat Metrics We also learned that Twitter is logging similar metrics for lists of prominent Democrat and Republican accounts, ostensibly to understand whether any features that they ship affect those sets of accounts equally. Now we know that conservative accounts tend to share more misinformation than liberal accounts on both Twitter and on Facebook. And, Musk has alleged that Democrats and Big Tech are colluding to enforce policy violation unequally across parties.\nBut if you have these ``partisan equality’’ stats as part of your ship criteria, perhaps on equal footing with policy violation frequency, you can see how this could really affect the types of health and safety features that actually make it to the site in production.\nThis code was then comically removed via pull requests from Twitter. Because once you delete something on GitHub, it just goes away. Right?\nwhich specific user groups, you might wonder? pic.twitter.com/wYSsUKm1pA\n— Colin Fraser (@colin_fraser) April 1, 2023 Twitter Blue Boost What’s more, we sorta knew that Twitter Blue users get a boost in feed ranking, but the code make it clear that it could double your score among people who don’t follow you, and quadruple it for those who do.\nNot sure what I expected, but interesting that first pull request on newly open-sourced @Twitter algo (https://t.co/kAVP0zdzki) is to downweight verified user multipliers. pic.twitter.com/PfqIdVTDnk\n— Caitlin Hudon (@beeonaposy) March 31, 2023 As Jonathan Stray pointed out, if this counts as a paid promotion, the FTC might require Twitter to label your tweets as ads. Now we kind of already knew this from Musks Twitter Blue announcement, but having evidence in the code might cross a different line for the FTC.\nSo what about the ackshual algorithm? What does this say about feed ranking?\nThe code itself is there but it’s missing …","date":1680480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680480000,"objectID":"4bd208fd76dd88324c9169a96b532095","permalink":"https://solmessing.netlify.app/post/twitter-the-algorithm/","publishdate":"2023-04-03T00:00:00Z","relpermalink":"/post/twitter-the-algorithm/","section":"post","summary":"Last Friday (2023-03-31) Twitter released what it calls “the algorithm,” which appears to be a highly redacted, incomplete part of code that governs the “for you” home timeline ranking system. And I saw nothing to suggest the parts of the code they put in the GitHub repository wasn’t authentic.\n","tags":[],"title":"What can we learn from 'The Algorithm,' Twitter's partial open-sourcing of it's feed-ranking recommendation system?","type":"post"},{"authors":["Minali Aggarwal","Jennifer Allen","Alexander Coppock","Dan Frankowski","Solomon Messing","Kelly Zhang","James Barnes","Andrew Beasley","Harry Hantman","Sylvan Zheng"],"categories":null,"content":" Supplimentary materials at end of manuscript Replication materials Media coverage: Nature ","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"809a0f9cc24fd9e35181b25a11b9e4b5","permalink":"https://solmessing.netlify.app/publication/aggarwal20232/","publishdate":"2023-01-12T00:00:00Z","relpermalink":"/publication/aggarwal20232/","section":"publication","summary":"We present the results of a massive, $8.9 million campaign-wide field experiment, conducted among 2 million moderate and low-information ``persuadable'' voters in five battleground states during the 2020 US Presidential election. Treatment group subjects were exposed to an eight-month-long advertising program delivered via social media, designed to persuade people to vote against Donald Trump and for Joe Biden. On average, the program neither increased or decreased turnout. We find evidence of differential turnout effects by modeled level of Trump support: the campaign increased voting among Biden leaners by 0.4 percentage points (SE: 0.2pp) and decreased voting among Trump leaners by 0.3 percentage points (SE: 0.3pp), for a difference-in-CATES of 0.7 points t(1035571) = -2.09, p = 0.036, DIC = 0.7 points, 95% CI = [-0.014, -0.00]). An important but exploratory finding is that the strongest differential effects appear in early voting data, which may inform future work on early campaigning in a post-COVID electoral environment. Our results indicate that differential mobilization effects of even large digital advertising campaigns in presidential elections are likely to be modest.","tags":null,"title":"A 2 million-person, campaign-wide field experiment shows how digital advertising affects voter turnout","type":"publication"},{"authors":["Sol Messing"],"categories":[],"content":"It’s becoming clear that the 2020 polls underestimated Trump’s support by anywhere from a 4-8 point margin depending on your accounting–a significantly worse miss than in 2016, when state polls were off but the national polls did relatively well.\nIn fact, this year we were better off using projections based on past vote history in each state to predict how things would go in battleground states, as I’ll show below.\nBut I also want to start to ask questions about what happened this time around. The polling from 2018 looked encouraging, convincing many pollsters that the post-2016 reckoning had fixed many issues called out in the 2016 AAPOR report on election polling. After 2018, FiveThirtyEight wrote that the “Polls are Alright”.\nBut the second Miami-Dade reported results from the 2020 election, we knew something was probably wrong with the 2020 polls.\nAs Stefan notes (we worked together at Pew Research Center’s Data Labs), the error seems slightly lower in key battleground states, though the polls missed big in WI, perhaps in part due to its horrifically bad voter file data.\nUnlike 2016, both state and national polls appeared to underestimate Trump’s support, as this early (Nov 7) analysis from Tom Wood shows:\nCurrent as to the afternoon on the 7th, and with Senate results too. pic.twitter.com/EGZGarRPNj\n— Tom Wood (@thomasjwood) November 7, 2020 Polling versus past votes Perhaps what surprised me the most about polling this time around was when I went to evaluate some election projections I put together in April that we used internally at Acronym to help evaluate where we might want to spend. I pulled in the NYTimes polling averages and compared them with the latest state-level presidential results from the AP. I then did the same for the April projections. Turns out the projections were significantly more accurate than the polling averages:\nWe used these projections, and other extant data (including the fact that there are two Senate races in play), when making what turned out to be a very lucky decision to start spending money in Georgia. We were one of the biggest and earliest spenders in that race.\nWhat are these projections? I simply took the last two state-level Presidential and U.S. House election totals, estimated each state’s “trajectory,” and added that to each state’s Democratic margin from the previous cycle.\n(Note that I also weighted 60-40 toward the Presidential results, and slightly regularized both the latest margin and the trajectory toward zero.)\nInforming this approach is work from Yair Ghitza describing what went wrong in 2016, which suggested polarization and other state-level trends would continue, in addition to national trends or “uniform swing.” This paper from @SimonJackman also deserves a big hat tip https://t.co/CTTpYDPwl2\n— Sol Messing (@SolomonMg) November 8, 2020 I should note that this may only have worked because of something peculiar about this election cycle–I haven’t gone an back-tested this approach or anything like that.\nSeems I was not the only one who noticed this kind of pattern:\nA similar observation from @gelliottmorris https://t.co/XSUAhGBZfb\n— Sol Messing (@SolomonMg) November 8, 2020 What went wrong: The Usual Suspects Humble-brag aside, it’s worth asking what might have gone wrong with polling in 2020?\nThe 2016 AAPOR report on election polling provides some guidance for how we might start to examine issues with the 2020 polls.\nUndecided voters: Undecideds broke toward Trump late in the election in 2016–polls found as many as 13 percent of voters were undecided on election day or planned to vote for a third party. According to Poynter, there were half as many of these voters in 2020, so this is unlikely to be as big a factor as in 2016.\nLow education non-response \u0026amp; adjustment: In 2016, individuals lower levels of education were much less likely to answer polls but still voted, and broke for Trump. The national polls adjusted for this but state level polls did not, which is partially why forecasting models that rely on state-level polls missed so hard.\nWhile many state-level pollsters did this in 2020, Pew Research Center still found problems with state level polling this time around, for example failing to adjust for race and education simultaneously–non-college whites are far more likely to support Trump than non-college non-whites.\nWhat’s more, pollsters adjusted only for college/non-college, which may not have been enough. They might need to use more fine grained adjustment–accounting for whether respondents have a high school degree and a college degree. Also error/missing data when people complete education in a survey means trouble if you want to fully fix the issue.\nVolunteerism \u0026amp; civic engagement: Even if you adjust for low levels of non-response among individuals with lower education, pollsters still may have problems reaching low civic engagement voters, a bias that seems to persist even after modeling/weighting adjustments. In the past this hasn’t …","date":1604793600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604793600,"objectID":"790c784c696b7c214cfb5c0ab22ebed6","permalink":"https://solmessing.netlify.app/post/what-the-polls-got-wrong-in-2020/","publishdate":"2020-11-08T00:00:00Z","relpermalink":"/post/what-the-polls-got-wrong-in-2020/","section":"post","summary":"It’s becoming clear that the 2020 polls underestimated Trump’s support by anywhere from a 4-8 point margin depending on your accounting–a significantly worse miss than in 2016, when state polls were off but the national polls did relatively well.\n","tags":[],"title":"Past vote data outperformed the polls. How did it go so wrong?","type":"post"},{"authors":["Sol Messing"],"categories":[],"content":"According to the latest polling research, Trump’s chances of hanging on to power beyond 2020 look pretty dismal. Nate Cohn published an impressive battleground poll from New York Times/Sienna showing Biden ahead of Trump by at least six points in pivotal states. The Economist’s forecast, powered by Elliott Morris and Andrew Gelman, is suggesting Biden is likely to get 64% of electoral college votes, and that if the election were held 100 times Biden would win 90 times to Trump’s 10.\nAt this point I would like to remind you of that feeling you felt on election night 2016. When a month earlier, CNN’s ‘Poll of Polls’ had Clinton up by 9 points and two prominent forecasters put Clinton’s chances at 99%. Remember that?\nI could probably stop there, but I’m not going to because although we’ve fixed some of the issues from 2016, we have COVID-19. And COVID will mess with our election in ways very likely to hurt Democrats, and I know of no pollster factoring this into their method or likely voter model.\nAfter 2016, Sean Westwood, Yphtach Lelkes and I began a multi-year research project (recently published in the Journal of Politics) and found that when you have high confidence that one candidate will win, you’re less likely to vote. The fact that everyone thought Clinton would win in 2016 shaped Comey’s decision to release his infamous letter that some believe cost Clinton the election, changed the way campaigns operated, and likely lowered Democratic turnout.\nIn addition to showing this in an experiment, one pattern that clearly pops out in the data we analyzed (ANES timeseries) is that people who think the leading candidate will win by quite a bit report voting at about a 3% lower rate. That’s in line with other research showing that early exit polls indicating one candidate is likely to win decrease turnout, and are more likely to affect Democrats. Yet this is by no means an upper bound—one study found more decisive exit polling depressed turnout by 11 points.\nWhile it’s if anything a noisy indicator of the influence Clinton’s ostensible lead may have had on Democrats compared with Republicans, the proportion of Democrats who thought Clinton would ‘win by quite a bit’ was much higher in 2016 than for Republicans, and much higher than it’d been in many years.\nTo be clear, I no longer occupy the role of dispassionate observer–I’m actively working in politics at the moment.\nSo while I like seeing Biden up, let me explain exactly why the margins we’re seeing could be a polling mirage.\nCOVID-19 Are pollsters accounting for the likely decline in urban turnout due to COVID-19? Not if they are assuming typical levels of turnout across urban and rural areas.\nMake no mistake, COVID-19 is already affecting the political process—look at voter registration. As many colleagues who regularly deal with registration data have warned me, the usual rush of new voter registrations, often from young voters, have “fallen off a cliff.” Registration numbers started stronger than ever as the new year began, but as 538 notes, fell to unprecedented levels in March as pandemic social distancing measures took effect.\nSo it’s already hurting Democrats in terms of new registrations, but what might all this mean on election day? At first blush, it may be tempting to say to yourself, “COVID is affecting old people more than the young, and they break conservative so the left is probably fine,” before feeling slightly ashamed that you’re thinking about strategic considerations before the loss of life and sadness this statement implies.\nThink a little deeper and you’ll likely realize that so far COVID-19 has affected left-leaning people in left-leaning places—non-White voters in urban areas far more than their suburban/rural counterparts. Even the recent surge in cases in sunbelt states is hitting urban and non-White regions hardest.\nWhat’s more, conservatives seem to be far more likely to be willing risk going out and about than liberals. A Pew study shows Republicans are far more likely to support lifting COVID restrictions quickly than Democrats.\nWith a deadly pandemic raging, will urban and non-urban voters go to the polls at the usual rates?\nPost-pandemic primary voting has meant a vast reduction in the number of polling places and a big increase in mail-in-ballots. We’re seeing this in post-pandemic primaries like this Tuesday’s in Kentucky, New York, and Virginia.\nIn New York’s primary, there were reports of missing mail in ballots. Kentucky also saw reports of long lines that disportionately hit Black neighborhoods, in a primary that will determine the Democrat who runs against Senate Majority Leader Mitch McConnell.\nWhat at first looks like maybe a silver lining is the surge in voting by mail-in ballot. And while Trump sees mail-in ballots as a threat to his re-election, the evidence is far from clear that widespread voting by mail would hurt his chances.\nOn the contrary, Stanford’s Andy Hall estimates that universal vote by mail should …","date":1592611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592611200,"objectID":"7b0afb24f5d96ef5976ea76f9a574f64","permalink":"https://solmessing.netlify.app/post/trumps-chances-are-better-than-they-look/","publishdate":"2020-06-20T00:00:00Z","relpermalink":"/post/trumps-chances-are-better-than-they-look/","section":"post","summary":"According to the latest polling research, Trump’s chances of hanging on to power beyond 2020 look pretty dismal. Nate Cohn published an impressive battleground poll from New York Times/Sienna showing Biden ahead of Trump by at least six points in pivotal states. The Economist’s forecast, powered by Elliott Morris and Andrew Gelman, is suggesting Biden is likely to get 64% of electoral college votes, and that if the election were held 100 times Biden would win 90 times to Trump’s 10.\n","tags":[],"title":"Trump's chances are better than they look","type":"post"},{"authors":[],"categories":[],"content":"Inspired by Donald Trump’s surprise victory over Hillary Clinton in the 2016 general election, Sean Westwood, Yphtach Lelkes and I set out to interrogate the question of whether elecion forecasts—particularly probablistic forecasts—might create a sense of inevitability, and ultimately lead people to stay home on election day.\nClinton herself was quoted in New York Magazine after the election:\nI had people literally seeking absolution… ‘I’m so sorry I didn’t vote. I didn’t think you needed me.’ I don’t know how we’ll ever calculate how many people thought it was in the bag, because the percentages kept being thrown at people — ‘Oh, she has an 88 percent chance to win!’\nIs it plausible that forecasting could have affected the election?\nFor this phenomena to affect an election, it must:\nbe visible in the media so it reaches potential voters, depress turnout, and affect one side more than the other. In the case of 2016, that means affecting Clinton’s supporters (and/or Clinton campaigners) more than Trump’s. We found evidence for all of the above. First, witness the rise of forecasts since 2008, when FiveThirtyEight first came on the scene:\nWhat’s more, there is good evidence that one side will be more affected. Our research (see results below) suggests that candidate who is ahead in the polls is more affected by probablistic forecasts. In 2016, that was Hillary.\nAnd irrespective of 2016, it’s outlets with a left-leaning audience that publish and cover election forecasts. The websites that present their poll aggregation results in terms of probabilities have left-leaning (negative) social media audiences—only realclearpolitics.com, which doesn’t emphasize win-probabilities, has a conservative audience:\nThese data come from the average self-reported ideology of people who share links to various sites hosting poll-aggregators on Facebook, data that come from this paper’s replication materials.\nWhen you look at the balance of coverage of probabilistic forecasts on major television broadcasts, there is more coverage on MSNBC, which has a more liberal audience.\nHow much influence do forecasters really have?\nIt’s increadibly difficult to tease out when one media outlet is influencing another. However, a freak event in 2018 allows us to get some traction on this question, and suggests that FiveThirtyEight’s 2018 coverage was highly influential.\nAfter FiveThirtyEight’s real-time forecast suddenely moved the the GOP’s odds of taking the House from single digits to about 60% at around 8:15PM, PredictIt’s odds on the GOP rose above 50-50, \u0026amp; U.S. government bond yields rose 2-4 basis points. FiveThirtyEight then altered it’s prediction system and the markets calmed down.\nThis spike seems to have occurred because a number of big, Republican-dominated districts started reporting returns before those that went toward Democrats and because it was making inferences from partial vote counts:\nThis was first reported by Colby Smith \u0026amp; Brian Greeley of FT.com. They report that because markets expected to see more inflation under a Republican House (high spending, low taxes) the U.S. Bond yield rose.\nWas this just a correlation? Possibly, but there was pretty much nothing else happening in the U.S., and it was like 1 am in Europe, as pointed out in the FT.com piece above.\nJosh Tucker suggested that 538 might be driving prediction markets back in 2012 in a Monkey Cage blogpost.\nOur research on forecasting and perception\nOur research shows that probablistic election forecasts make a race look less competitive. Participants in a national probability survey-experiment were substantially more certain that one candidate would win a hypothetical race after seeing a probablistic forecast than after seeing the equivalent vote share estimate and margin of error. This is a big effect—those are confidence intervals not standard errors, with p-values below $$10^{-11}$$.\nWhy do people do this?\nMore research is needed here but we do have some leads. First, small differences in the election metric most familiar to the public—vote share estimates—generally correspond to very large differences in the probability of a candidate’s chance of victory.\nAndy Gelman referenced this in passing in a 2012 blogpost questioning the decimal precision (0.1 percent) that 538 used to communicate its forecast on its website:\nThat’s right: a change in 0.1 of win probability corresponds to a 0.004 percentage point share of the two-party vote. I can’t see that it can possibly make sense to imagine an election forecast with that level of precision…\nSecond, people sometimes confuse probabilistic forecasts with vote share projections, and incorrectly conclude that a candidate is projected to say win 85% percent of the vote, rather than to having an 85% chance of winning the election. About 1 in 10 peope did this in our experiment.\nAs Joshua Benton pointed out in a tweet, TalkingPointsMemo.com made this very mistake:\nFinally, people tend to think in qualitative terms about …","date":1589860109,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589860109,"objectID":"8476d790ce80588cccb6543c5dbdb394","permalink":"https://solmessing.netlify.app/project/projecting_confidence/","publishdate":"2020-05-18T22:48:29-05:00","relpermalink":"/project/projecting_confidence/","section":"project","summary":"How the Probabilistic Horse Race Demobilizes the Public","tags":[],"title":"Projecting Confidence","type":"project"},{"authors":[],"categories":[],"content":"On January 17, 2020 my team at Facebook launched one of the largest social science data sets ever constructed. It’s meant to facilitate research on misinformation from across the web, shared and spread on Facebook.\nFull details on the release here.\nWe also released the URL santization framework, which I implemented (and which my SWE colleagues refactored).\nWhat makes this data release unprecedented is that it contains exposure data describing external links that billions of users saw and read while using the site.\nThe data set goes beyond URL-level data, breaking down exposure and interactions by month, country, age, gender, and in the U.S., political page affinity (see Barbera et al 2015).\nThe data contain two tables: (1) a “URL attributes” table describing the 38 million URLs in the data set, including how many times users tagged those posts as containing misinformation, harassment, etc. and (2) a “breakdown” table, which aggregates counts of actions taken on urls, broken out by user demographics and URL attributes.\nThe technical documentation reflects more work than most papers I’ve written: . This list of authors reflects the scale of this massive team effort, and that’s before you include increadibly helpful advice we got from a number of computer scientists in the academy listed in the acknowledgements.\nPerhaps most importantly, this release provides guarantees about anonymity in an incredibly rigorous way–action-level differential privacy, while preserving more underlying signal in the data.\n","date":1589760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760000,"objectID":"b14799ea11298f03030a016bc10937b1","permalink":"https://solmessing.netlify.app/project/condor_data_release/","publishdate":"2020-05-18T00:00:00Z","relpermalink":"/project/condor_data_release/","section":"project","summary":"Largest ever social science data set, released under differential privacy","tags":[],"title":"Facebook Condor URLs Data Release","type":"project"},{"authors":[],"categories":[],"content":"The Impression of Influence: Legislator Communication, Representation, and Democratic Accountability Princeton University Press, 2015. With Justin Grimmer and Sean Westwood\nMedia: Mischiefs of Faction. ","date":1589673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589673600,"objectID":"f0402bccd43759784e08f521443e4da3","permalink":"https://solmessing.netlify.app/project/impression_of_influence/","publishdate":"2020-05-17T00:00:00Z","relpermalink":"/project/impression_of_influence/","section":"project","summary":"A book on how Members of Congress use Credit Claiming   ","tags":[],"title":"Impression of Influence","type":"project"},{"authors":["Sol Messing"],"categories":[],"content":"Do you remember the night of Nov 8, 2016? I was glued to election coverage and obsessively checking probabilistic forecasts, wondering whether Clinton might do so well that she’d win in places like my home state of Arizona. Although FiveThirtyEight had Clinton’s chances at beating Trump at around 70%, most other forecasters had her at around 90%.\nWhen she lost, many on both sides of the aisle were shocked. My co-authors and I wondered if America’s seeming confidence in a Clinton victory wasn’t driven in part by increasing coverage of probabilistic forecasts. And, if a Clinton victory looked inevitable, what did that do to turnout?\nWe weren’t alone. Clinton herself was quoted in New York Magazine after the election:\nI had people literally seeking absolution… ‘I’m so sorry I didn’t vote. I didn’t think you needed me.’ I don’t know how we’ll ever calculate how many people thought it was in the bag, because the percentages kept being thrown at people — ‘Oh, she has an 88 percent chance to win!’\nEnter our recent blog post and paper released on SSRN, “Projecting confidence: How the probabilistic horse race confuses and de-mobilizes the public,” by Sean Westwood, Solomon Messing, and Yphtach Lelkes. While our work cannot definitively say whether probabilistic forecasts played a decisive role in the 2016 election, it does indeed show that compared to more conventional vote share projections, probabilistic forecasts can confuse people, can give people more confidence that the candidate depicted as being ahead will win, may decrease turnout, and that liberals in the U.S. are more likely to encounter them. We appreciate the media attention to this work, including coverage by the Washington Post, New York Magazine, and the Political Wire. What’s more, FiveThirtyEight devoted much of their Feb. 12 Politics Podcast to a spirited, and at points critical discussion of our work. We are open to criticism and will respond to some of the questions raised in this post. Below, we’ll show that the evidence in our study and in other research is not inconsistent with our headline, as the hosts suggest—we’ll detail the evidence that probabilistic forecasts confuse people, irrespective of their technical accuracy. We’ll also discuss where we agree with the podcast hosts. Furthermore, we’ll discuss a few topics which, judging from the hosts discussion, may not have come through clearly enough in our paper. We’ll reiterate what this work contributes to social science—how the paper adds to our understanding of how people think about probabilistic forecasts and how they may decrease voting, particularly for the leading candidate’s supporters and among liberals in the U.S. We’ll then walk readers through the way we mapped vote share projections to probabilities in the study. Finally we’ll discuss why this work matters, and conclude by pointing out future research we’d like to see in this area.\nWhat’s new here?\nThe research contains a number findings that are new to social science:\nPresenting forecasted win-probabilities gives potential voters the impression that one candidate will win more decisively, compared with vote share projections (Study 1). Higher win probabilities, but not vote share estimates, decrease voting in the face of the trade-offs embedded in our election simulation (Study 2). This helps confirm the findings in Study 1 and adds to the evidence from past research that people vote at lower rates when they perceive an election to be uncompetitive. In 2016, probabilistic forecasts were covered more extensively than in the past and tended to be covered by outlets with more liberal audiences. Where we agree\nIf what you care about is conveying an accurate sense of whether one candidate will win, probabilistic forecasts do this slightly better than vote share. And, they seem to give people an edge on accuracy when interpreting the vote share if your candidate is behind. Of course, people can be confused and still end up being accurate, as we’ll discuss below.\nWe also agree that people often do not accurately judge the likelihood of victory after seeing a vote share projection. That makes sense because, as the study shows, people appear to largely ignore the margin of error, which they’d need to map between vote share estimates and win probabilities.\nWe also agree that a lot of past work shows that people stay home when they think an election isn’t close. What we’re adding to that body of work is evidence that compared with vote share projections, probabilistic forecasts give people the impression that one candidate will win more decisively, and may thus more powerfully affect turnout.\nDoes the evidence in our study contradict our headline?\nOur headline isn’t about accuracy, it’s about confusion. And the evidence from this research and past work taken as a whole suggests that probabilistic forecasts confuse people — something that came up at the end of segment — even if the result sometimes is technically higher accuracy.\n1. …","date":1587859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587859200,"objectID":"f4366daf83642214038e5de247bbc2a2","permalink":"https://solmessing.netlify.app/post/response-to-fivethirtyeights-podcast-about-our-paper-projecting-confidence/","publishdate":"2020-04-26T00:00:00Z","relpermalink":"/post/response-to-fivethirtyeights-podcast-about-our-paper-projecting-confidence/","section":"post","summary":"Do you remember the night of Nov 8, 2016? I was glued to election coverage and obsessively checking probabilistic forecasts, wondering whether Clinton might do so well that she’d win in places like my home state of Arizona. Although FiveThirtyEight had Clinton’s chances at beating Trump at around 70%, most other forecasters had her at around 90%.\n","tags":[],"title":"Why Election Forecasting Matters","type":"post"},{"authors":["Sol Messing"],"categories":[],"content":" My last post railed against the bad visualizations that people often use to plot quantitive data by groups, and pitted pie charts, bar charts and dot plots against each other for two visualization tasks. Dot plots came out on top. I argued that this is because humans are good at the cognitive task of comparing position along a common scale, compared to making judgements about length, area, shading, direction, angle, volume, curvature, etc.—a finding credited to Cleveland and McGill. I enjoyed writing it and people seemed to like it, so I’m continuing my visualization series with the scatterplot.\nScatterplots A scatterplot is a two-dimensional plane on which we record the intersection of two measurements for a set of case items–usually two quantitative variables. Just as humans are good at comparing position along a common scale in one dimension, our visual capabilities allow us to make fast, accurate judgements and recognize patterns when presented with a series of dots in two dimensions. This makes the scatterplot a valuable tool for data analysts both when exploring data and when communicating results to others.\nIn this post—part 1—I’ll demonstrate various uses for scatterplots and outline some strategies to help make sure key patterns are not obscured by the scale or qualitative group-level differences in the data (e.g., the relationship between test scores and income differs for men and women). The motivation in this post is to come up with a model of diamond prices that you can use to help make sure you don’t get ripped off, specified based on insight from exploratory scatterplots combined with (somewhat) informed speculation. In part 2, I’ll discuss the use of panels aka facets aka small multiples to shed additional light on key patterns in the data, and local regression (loess) to examine central tendencies in the data. There are far fewer bad examples of this kind of visualization in the wild than the 3D barplots and pie charts mocked in my last post, though I was still able to find this lovely scatterplot + trend-line.\nScatterplots and the Cartesian coordinate system The scatterplot has a richer history than the visualizations I wrote about in my last post. The scatterplot’s face forms a two-dimensional Cartesian coordinate system, and DeCartes’ invention/discovery of this eponymous plane in around 1657 represents one of the most fundamental developments in science. The Cartesian plane unites measurement, algebra, and geometry, depicting the relationship between variables (or functions) visually. Prior to the Cartesian plane, mathematics was divided into algebra and geometry, and the unification of the two made many new developments possible. Of course, this includes modern map-making—cartography, but the Cartesian plane was also an important step in the development of calculus, without which very little of our modern would would be possible.\nThe scatterplot is a powerful tool to help understand the relationship between variables, and especially if that relationship is non-linear. Say you want to get a sense of whether you’re paying the right price when shopping for a diamond. You can use data on the price and characteristics of many diamonds to help figure out whether the price advertised for any given diamond is reasonable, and you can use scatterplots to help figure out how to model that data in a sensible way. Consider the important relationship between the price of a diamond and its carat weight (which corresponds to its size):\nA few things pop out right away. We can see a non-linear relationship, and we can also see that the dispersion (variance) of the relationship also increases as carat size increases. With just a quick look at a scatterplot of the data, we’ve learned two important things about the functional relationship between price and carat size. And, we also therefore learned that running a linear model on this data as-is would be a bad idea.\nDiamonds If you’ve ever used R, you’ve probably seen references to the diamonds data set that ships with Hadley Wickham’s ggplot2. It records the carat size and the price of more than 50 thousand diamonds, from http://www.diamondse.info/ collected in in 2008, and if you’re in the market for a diamond, exploring this data set can help you understand what’s in store and at what price point. This is particularly useful because each diamond is unique in a way that isn’t true of most manufactured products we are used to buying—you can’t just plug a model number and look up the price on Amazon. And even an expert cannot cannot incorporate as much information about price as a picture of the entire market informed by data (though there’s no substitute for qualitative expertise to make sure your diamond is what the retailer claims).\nBut even if you’re not looking to buy a diamond, the socioeconomic and political history of the diamond industry is fascinating. Diamonds birthed the mining industry in South Africa, which is now by far the largest and most …","date":1580601600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580601600,"objectID":"280f6c7dfb3af4294f0a954eabc201ba","permalink":"https://solmessing.netlify.app/post/visualization-series-scatterplot-understanding-the-diamond-market/","publishdate":"2020-02-02T00:00:00Z","relpermalink":"/post/visualization-series-scatterplot-understanding-the-diamond-market/","section":"post","summary":"Second post in my data visualization series on scatterplots and regression analysis","tags":[],"title":"Know your data - Pricing diamonds using scatterplots and predictive models","type":"post"},{"authors":["Solomon Messing","Christina DeGregorio","Bennett Hillenbrand","Gary King","Saurav Mahanti","Chaya Nayak","Nate Persily"],"categories":null,"content":" Largest ever social science data set released, protected using action-level differential privacy. See also Social Science One’s annoucement. Media coverage: Science, Nature, Poynter, Wired, Financial Times, Tech Crunch, The Verge. ","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"aa0019151390f46b5fa17fb066ba25f4","permalink":"https://solmessing.netlify.app/publication/messing-2020/","publishdate":"2020-06-02T02:04:47.467918Z","relpermalink":"/publication/messing-2020/","section":"publication","summary":"One of the largest social science data sets ever constructed, meant to facilitate research on misinformation from across the web, shared and spread on Facebook. It contains exposure data describing external links that billions of users saw and read while using the site. The data set goes beyond URL-level data, breaking down exposure and interactions by month, country, age, gender, and in the U.S., political page affinity (see Barbera et al 2015).   ","tags":null,"title":"Facebook Privacy-Protected Full URLs Data Set","type":"publication"},{"authors":["Daniel Kifer","Solomon Messing","Aaron Roth","Abhradeep Thakurta","Danfeng Zhang"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"8c7294b70c5b70c0f008671c7bfdca5a","permalink":"https://solmessing.netlify.app/publication/kifer-2020-guidelines/","publishdate":"2020-06-02T02:04:47.467086Z","relpermalink":"/publication/kifer-2020-guidelines/","section":"publication","summary":"Differential privacy is an information theoretic constraint on algorithms and code. It provides quantification of privacy leakage and formal privacy guarantees that are currently considered the gold standard in privacy protections. In this paper we provide an initial set of \"best practices\" for developing differentially private platforms, techniques for unit testing that are specific to differential privacy, guidelines for checking if differential privacy is being applied correctly in an application, and recommendations for parameter settings. The genesis of this paper was an initiative by Facebook and Social Science One to provide social science researchers with programmatic access to a URL-shares dataset. In order to maximize the utility of the data for research while protecting privacy, researchers should access the data through an interactive platform that supports differential privacy. The intention of this paper is to provide guidelines and recommendations that can generally be re-used in a wide variety of systems. For this reason, no specific platforms will be named, except for systems whose details and theory appear in academic papers.","tags":null,"title":"Guidelines for Implementing and Auditing Differentially Private Systems","type":"publication"},{"authors":["Sol Messing"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic! Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post\u0026#39;s title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post’s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://solmessing.netlify.app/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://solmessing.netlify.app/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Sean Westwood","Solomon Messing","Yphtach Lelkes"],"categories":null,"content":" Supplimentary materials Cited by FiveThirthyEight’s Politics Podcast as influential in decision to change forecast presentation. Media coverage: Washington Post, New York Magazine, Political Wire. ","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"2ee4f07a9fc739fed229a2d87e54bfec","permalink":"https://solmessing.netlify.app/publication/wlm-2019-projecting/","publishdate":"2020-06-02T02:04:47.465593Z","relpermalink":"/publication/wlm-2019-projecting/","section":"publication","summary":"Recent years have seen a dramatic change in horserace coverage of elections in the U.S.---shifting focus from late-breaking poll numbers to sophisticated meta-analytic forecasts that emphasize candidates' chance of victory. Could this shift in the political information environment affect election outcomes? We use experiments to show that forecasting increases certainty about an election's outcome, confuses many, and decreases turnout. Furthermore, we show that election forecasting has become prominent in the media, particularly in outlets with liberal audiences, and show that such coverage tends to more strongly affect the candidate who is ahead---raising questions about whether they contributed to Trump's victory over Clinton in 2016. We bring empirical evidence to this question, using ANES data to show that Democrats and Independents expressed unusual confidence in a decisive 2016 election outcome---and that the same measure of confidence is associated with lower reported turnout.","tags":null,"title":"Projecting confidence: How the probabilistic horse race confuses and demobilizes the public","type":"publication"},{"authors":["Fanny Chapelin","Aman Khurana","Mohammad Moneeb","Florette K Gray Hazard","Chun Fai Ray Chan","Hossein Nejadnik","Dita Gratzinger","Solomon Messing","Jason Erdmann","Amitabh Gaur"," others"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"7ffc5c7b4880707290b23b30678b540d","permalink":"https://solmessing.netlify.app/publication/chapelin-2019-tumor/","publishdate":"2020-06-02T02:04:47.466292Z","relpermalink":"/publication/chapelin-2019-tumor/","section":"publication","summary":"Purpose: While imaging matrix-associated stem cell transplants aimed for cartilage repair in a rodent arthritis model, we noticed that some transplants formed locally destructive tumors. The purpose of this study was to determine the cause for this tumor formation in order to avoid this complication for future transplants.  Procedures: Adipose-derived stem cells (ADSC) isolated from subcutaneous adipose tissue were implanted into 24 osteochondral defects of the distal femur in ten athymic rats and two immunocompetent control rats. All transplants underwent serial magnetic resonance imaging (MRI) up to 6 weeks post-transplantation to monitor joint defect repair. Nine transplants showed an increasing size over time that caused local bone destruction (group 1), while 11 transplants in athymic rats (group 2) and 4 transplants in immunocompetent rats did not. We compared the ADSC implant size and growth rate on MR images, macroscopic features, histopathologic features, surface markers, and karyotypes of these presumed neoplastic transplants with non-neoplastic ADSC transplants.  Results: Implants in group 1 showed a significantly increased two-dimensional area at week 2 (p = 0.0092), 4 (p = 0.003), and 6 (p = 0.0205) compared to week 0, as determined by MRI. Histopathological correlations confirmed neoplastic features in group 1 with significantly increased size, cellularity, mitoses, and cytological atypia compared to group 2. Six transplants in group 1 were identified as malignant chondrosarcomas and three transplants as fibromyxoid sarcomas. Transplants in group 2 and immunocompetent controls exhibited normal cartilage features. Both groups showed a normal ADSC phenotype; however, neoplastic ADSC demonstrated a mixed population of diploid and tetraploid cells without genetic imbalance.  Conclusions: ADSC transplants can form tumors in vivo. Preventive actions to avoid in vivo tumor formations may include karyotyping of culture-expanded ADSC before transplantation. In addition, serial imaging of ADSC transplants in vivo may enable early detection of abnormally proliferating cell transplants. ","tags":null,"title":"Tumor formation of adult stem cell transplants in rodent arthritic joints","type":"publication"},{"authors":["Sol Messing"],"categories":[],"content":"Regression models are a cornerstone of modern social science. They’re at the heart of efforts to estimate causal relationships between variables in a multivariate environment and are the basic building blocks of many machine learning models. Yet social scientists can run into a lot of situations where regression models break.\nFamed social psychologist Richard Nisbett recently argued that regression analysis is so misused and misunderstood that analyses based on multiple regression “are often somewhere between meaningless and quite damaging.” (He was mainly talking about cases in which researchers publish correlational results that are covered in the media as causal statements about the world.)\nBelow, I’ll walk through some of the potential pitfalls you might encounter when you fire up your favorite statistical software package and run regressions. Specifically, I’ll be using simulation in R as an educational tool to help you better understand the ways in which regressions can break.\nUsing simulations to unpack regression\nThe idea of using R simulations to help understand regression models was inspired by Ben Ogorek’s post on regression confounders and collider bias.\nThe great thing about using simulation in this way is that you control the world that generates your data. The code I’ll introduce below represents the true data-generating process,since I’m using R’s random number generators to simulate the data. In real life, of course, we only have the data we observe, and we don’t really know how the data-generating process works unless we have a solid theory (like Newtonian physics or evolution) where the system of relevant variables and causal relationships is well understood and to which there is really no analogous phenomenon in social science.\nWhat I’ll do here is create a dataset based on two random standard normal variables by simulating them using the rnorm() function, which draws random values from a normal distribution with mean 0 and standard deviation 1, unless you specify otherwise. I’ll create a functional relationship between y and x such that a 1 unit increase in x will be associated with a .4 unit increase in y.\n# make the code reproducible by setting a random number seed set.seed(100) # When everything works: N \u0026lt;- 1000 x \u0026lt;- rnorm(N) y \u0026lt;- .4 * x + rnorm(N) hist(x) hist(y) # Now estimate our model: summary(lm(y ~ x)) Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -3.0348 -0.7013 0.0085 0.6212 3.1688 Coefficients: Estimate Std. Error t value Pr(\u0026gt;|t|) (Intercept) 0.003921 0.031039 0.126 0.899 x 0.413415 0.030129 13.722 \u0026lt;2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 0.9814 on 998 degrees of freedom Multiple R-squared: 0.1587,\tAdjusted R-squared: 0.1579 F-statistic: 188.3 on 1 and 998 DF, p-value: \u0026lt; 2.2e-16 # Plot it library(ggplot2) qplot(x, y) + geom_smooth(method=\u0026#39;lm\u0026#39;) + theme_bw() + ggtitle(\u0026#34;The Perfect Regression\u0026#34;) Notice that the model estimates the functional relationship between x and y that I simulated quite well. The plot looks like this:\nWhat about omitted variables? Our machinery actually still works if there is another factor causing y, as long as it is uncorrelated with x.\nThe dreaded omitted variable bias\nOmitted variable bias (OVB) is much feared, and judging by the top internet search results, not well understood. Some top sources say it occurs when “an important” variable is missing or when a variable that “is correlated” with both x and y is missing. I even found a university econometrics course that defined OVB this way.\nBut neither of those definitions are quite right. OVB occurs when a variable that causes y is missing from the model (and is correlated with x). Let’s call that variable w. Because w is in play when we consider the causal relationship between x and y, it’s often referred to as “endogenous” or a “confounding variable.”\nThe example below first demonstrates that w, our confounding variable, will bias our results if we fail to include it in our model. The next two examples are essentially a re-telling of the post I mentioned above on collider bias, but emphasizing slightly different points.\nw \u0026lt;- rnorm(N) x \u0026lt;- .5 * w + rnorm(N) y \u0026lt;- .4 * x + .3 * w + rnorm(N) m1 \u0026lt;- lm(y ~ x) summary (m1) # Omitted variable bias Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -3.2190 -0.7025 0.0314 0.7120 3.1158 Coefficients: Estimate Std. Error t value Pr(\u0026gt;|t|) (Intercept) 0.01126 0.03310 0.34 0.734 x 0.50179 0.03049 16.46 \u0026lt;2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 1.046 on 998 degrees of freedom Multiple R-squared: 0.2135,\tAdjusted R-squared: 0.2127 F-statistic: 270.9 on 1 and 998 DF, p-value: \u0026lt; 2.2e-16 There it is: classic omitted variable bias. We only observed x, and the influence of the omitted variable w was attributed to x in our model. If you re-rerun the regression with w in the model, you no longer get biased estimates.\nm2 \u0026lt;- lm(y ~ x + w) …","date":1528848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"a167f7f26122792b24d60fbe134ef5ee","permalink":"https://solmessing.netlify.app/post/how-to-break-regression/","publishdate":"2018-06-13T00:00:00Z","relpermalink":"/post/how-to-break-regression/","section":"post","summary":"Regression models are a cornerstone of modern social science. They’re at the heart of efforts to estimate causal relationships between variables in a multivariate environment and are the basic building blocks of many machine learning models. Yet social scientists can run into a lot of situations where regression models break.\n","tags":[],"title":"How to break regression","type":"post"},{"authors":["Sol Messing"],"categories":[],"content":"This post presents a replication of Messing et al. (2016, study 2), which showed that exposure to darker images of Barack Obama increased stereotype activation, as indicated by the tendency to finish incomplete word prompts---such as “W E L _ _ _ _”---in stereotype-consistent ways (“WELFARE”).\nOverall, the replication shows that darker images of even counter-stereotypical exemplars like Barack Obama can increase stereotype activation, but that the strength of the effect is weaker than conveyed in the original study. A reanalysis of the original study conducted in the course of this replication effort unearthed a number of problems that, when corrected, yield estimates of the effect that are consistent with those documented in the replication. This reanalysis also follows.\nI\u0026#39;m posting this to\ndisseminate a corrected version of the original study; show how I found those problems with the original study in the course of conducting this replication; circulate these generally confirmatory findings, along with a pooled analysis revealing a stronger effect among conservatives; and provide a demonstration of how replication almost always enhances our knowledge about the original research, which I hope may encourage others to invest the time and money in such efforts. First some context.\nThe original study that formed the basis of the manuscript shows that more negative campaign ads in 2008 were also more likely to contain darker images of President Obama. In 2009 when I started this work, I was most proud of the method to collect data on skin complexion outlined in study 1. I included another study, what\u0026#39;s now study 3, which shows that 2012 ANES survey-takers were more likely to respond negatively to Chinese characters after being presented with darker images of Obama (this is called the Affect Misattribution Procedure (AMP)). But the AMP was not a true experiment and a reviewer was concerned that Study 3 did not provide sufficiently rigorous, causal evidence that darker images alone can cause negative affect. So I conducted an experiment that would establish a causal link between darker images of Obama and something I thought was even more important---stereotype activation. There were strong reasons to expect this effect based on past lab studies showing links between darker skin and negative stereotypes about Blacks, and past observational studies showing far more negative socioeconomic outcomes across the board among darker versus lighter skinned Black Americans. We found an effect and published the three studies.\nThis replication effort was prompted by a post-publication reanalysis and critique, which raised questions about potential weaknesses in the original analysis. My aim in replicating the study was to bring new data to the discussion and make sure we hadn’t polluted the literature with a false discovery.\nThe main objection was the way we formed our stereotype consistency index. The items assessing stereotype consistency comprised 11 words with missing blank spaces (e.g., L A _ _). Each fragment had as one possible solution a stereotype-related completion. The complete list follows: L A _ _ (LAZY): C R _ _ _ (CRIME); _ _ O R (POOR); R _ _ (RAP); WEL _ _ _ _ (WELFARE); _ _ C E (RACE); D _ _ _ Y (DIRTY); B R _ _ _ _ _ (BROTHER); _ _ A C K (BLACK); M I _ _ _ _ _ _ (MINORITY); D R _ _ (DRUG).\nThe author pointed out that there were many potential ways to analyze the original data---he claimed over 16 thousand. Yet very few of these are consistent with generally accepted research practices. We\u0026#39;ve known, arguably since the 16th century, that combining several measures reduces measurement error and hence variance in estimation. This is particularly important in social science, and especially for this particular study---it would be unwise to attempt to use a single word completion or an arbitrary subset thereof to measure a complex, noisy construct like stereotype activation as measured via a word completion game. Rather, taking the average or constructing an index based on clustering several measures should be expected to result in far less measurement error, which is what we did.\nStill, I am sympathetic to concerns about the garden of forking paths, which is part of the motivation for this replication.\nIn the original study, I formed this index based on what I judged to be the most unambiguously negative word-completions (lazy, dirty, poor), consistent with past work suggesting that darker complexion activates the most negative stereotypes about Blacks. I calculated that these were the three variables that also maximized interclass correlation (ICC). As a robustness check, I also computed a measure that maximized alpha reliability (AR). This measure contained more items, and also seemed to include stereotype-consistent word completions that were on balance negative---lazy, dirty, poor, crime, black, and welfare. I should have but did not report results based on a simple average of these items, which was not …","date":1508112000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508112000,"objectID":"3be66141785515b63c646ac8b7c8fa93","permalink":"https://solmessing.netlify.app/post/replication_of_bias_in_the_flesh/","publishdate":"2017-10-16T00:00:00Z","relpermalink":"/post/replication_of_bias_in_the_flesh/","section":"post","summary":"Replication of Study 2 in \"Bias in the Flesh: Skin Complexion and Stereotype Consistency in Political Campaigns\"","tags":[],"title":"Replication of 'Bias in the Flesh'","type":"post"},{"authors":["Justin Grimmer","Solomon Messing","Sean J Westwood"],"categories":null,"content":"- [Replication materials](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/BQMLQW). - [Software implementation](https://github.com/SolomonMg/HetSL) (under development) ","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"73a96689e3afd7f02aca578fdc14fedb","permalink":"https://solmessing.netlify.app/publication/grimmer-2017-estimating/","publishdate":"2020-06-02T02:04:47.460136Z","relpermalink":"/publication/grimmer-2017-estimating/","section":"publication","summary":"Randomized experiments are increasingly used to study political phenomena because they can credibly estimate the average effect of a treatment on a population of interest. But political scientists are often interested in how effects vary across subpopulations---heterogeneous treatment effects---and how differences in the content of the treatment affects responses---the response to heterogeneous treatments. Several new methods have been introduced to estimate heterogeneous effects, but it is difficult to know if a method will perform well for a particular data set. Rather than using only one method, we show how an ensemble of methods---weighted averages of estimates from individual models increasingly used in machine learning---accurately measure heterogeneous effects. Building on a large literature on ensemble methods, we show how the weighting of methods can contribute to accurate estimation of heterogeneous treatment effects and demonstrate how pooling models lead to superior performance to individual methods across diverse problems. We apply the ensemble method to two experiments, illuminating how the ensemble method for heterogeneous treatment effects facilitates exploratory analysis of treatment effects. ","tags":null,"title":"Estimating heterogeneous treatment effects and the effects of heterogeneous treatments with ensemble methods","type":"publication"},{"authors":["Patrick van Kessel, Adam G Hughes, Nick Judd, Rachel Blum, Brian Broderick Solomon Messing"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"d72021c34d2d19b7f54c5d3c3d35f01e","permalink":"https://solmessing.netlify.app/publication/solomon-2017-partisan/","publishdate":"2020-06-02T02:04:47.46401Z","relpermalink":"/publication/solomon-2017-partisan/","section":"publication","summary":"Partisan criticism generates most engagement in social media; most liberal and conservative legislators, party leadership more likely to `go negative'","tags":null,"title":"Partisan Conflict and Congressional Outreach","type":"publication"},{"authors":["Solomon Messing","Maria Jabon","Ethan Plaut"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"60026b3d5e7fe991ef729e9cb082798e","permalink":"https://solmessing.netlify.app/publication/messing-2016-bias/","publishdate":"2020-06-02T02:04:47.448293Z","relpermalink":"/publication/messing-2016-bias/","section":"publication","summary":"There is strong evidence linking skin complexion to negative stereotypes and adverse real-world outcomes. We extend these findings to political ad campaigns, in which skin complexion can be easily manipulated in ways that are difficult to detect. Devising a method to measure how dark a candidate appears in an image, this paper examines how complexion varied with ad content during the 2008 presidential election campaign (study 1). Findings show that darker images were more frequent in negative ads---especially those linking Obama to crime---which aired more frequently as Election Day approached. We then conduct an experiment to document how these darker images can activate stereotypes, and show that a subtle darkness manipulation is sufficient to activate the most negative stereotypes about Blacks---even when the candidate is a famous counter-stereotypical exemplar---Barack Obama (study 2). Further evidence of an evaluative penalty for darker skin comes from an observational study measuring affective responses to depictions of Obama with varying skin complexion, presented via the Affect Misattribution Procedure in the 2008 American National Election Study (study 3). This study demonstrates that darker images are used in a way that complements ad content, and shows that doing so can negatively affect how individuals evaluate candidates and think about politics.","tags":null,"title":"Bias in the flesh: Skin complexion and stereotype consistency in political campaigns","type":"publication"},{"authors":["Eytan Bakshy","Sol Messing"],"categories":[],"content":"Earlier this month, we published an early access version of our paper in ScienceExpress (Bakshy et al. 2015), “Exposure to ideologically diverse news and opinion on Facebook.” The paper constitutes the first attempt to quantify the extent to which ideologically cross-cutting hard news and opinion is shared by friends, appears in algorithmically ranked News Feeds, and is actually consumed (i.e., click through to read).\nWe are grateful for the widespread interest this paper, which grew out of two threads of related research that we began nearly five years ago: Eytan and Lada\u0026#39;s work on the role of social networks in information diffusion (Bakshy et al. 2012) and Sean and Solomon\u0026#39;s work on selective exposure in social media (Messing and Westwood 2012).\nWhile Science papers are explicitly prohibited from suggesting future directions for research, we would like to shed additional light on our study and raise a few questions that we would be excited to see addressed in future work.\nTradeoffs when Selecting a Population\nThere were tradeoffs when deciding on who to include in this study. While we could have examined all U.S. adults on Facebook, we focused on people who identify as liberals or conservatives and encounter hard news, opinion, and other political content in social media regularly. We did so because many important questions around “echo chambers” and “filter bubbles\u0026#34;on Facebook relate to this subpopulation, and we used self-reported ideological preferences to define it.\nUsing self-reported ideological preferences in online profiles is not the only a way to measure ideology or define the population of interest. Yet, people who publicly identify as liberals or conservatives in their Facebook profiles are an interesting and important subpopulation worthy of study for many reasons. As Hopkins and King 2010 have pointed out, studying the expression and behavior of those who are politically engaged online is of interest to political scientists studying activists (Verba, Schlozman, and Brady 1995), the media (Drezner and Farrell 2004), public opinion (Gamson 1992), social networks (Adamic and Glance 2005; Huckfeldt and Sprague 1995), and elite influence (Grindle 2005; Hindman, Tsioutsiouliklis, and Johnson 2003; Zaller 1992).\nThis subpopulation has limitations and is not the only population of interest. The data are not appropriate for those who seek estimates of the entire U.S. public, people without strong opinions, or people not on Facebook (at least not without additional extrapolation, re-weighting, additional evidence, etc.). While our data could plausibly also provide good estimates of the population of people who are ideologically active and have clear preferences, we are not claiming that\u0026#39;s necessarily the case---that remains to be determined in future work.\nWe\u0026#39;d like to help other researchers looking to study other populations understand more about the population we\u0026#39;ve defined. An important question in this regard is what proportion of active U.S. adults actually report an identifiable left/right/center ideology in their profile. That number is 25%, or 10.1 million people.\nIt\u0026#39;s also informative to examine the proportion of those users who provide identifiable profile affiliations conditional on demographics and Facebook usage:\nAge Percent reporting ideological affiliation 18-24 21.60% 25-44 28.50% 45-64 24.30% 65+ 21.40% Gender Percent reporting ideological affiliation Female 21.90% Male 30.60% Login Days Percent reporting ideological affiliation 105-140 18.90% 140-185 26.70% Clearly those who report an ideology in their profile tend to be more active on Facebook. They are also more likely to be men, which is consistent with the well-documented gender gap in American politics (Box-Steffensmeier 2004).\nIt\u0026#39;s possible that these individuals differ from other Facebook users in other ways. It seems plausible to expect these people to have higher levels of political interest, a stronger sense of political ideology and political identity, and to be more likely to be active in politics than most others on Facebook. It\u0026#39;s also possible that these individuals are more extroverted than the average user, especially in the somewhat taboo domain of politics. These possibilities also strike us as interesting questions for study in future work.\nHow to Measure Ideology\nWe hope others will replicate this work using other populations and ways of measuring ideology, which will provide a broader view of exposure to political media. Data on ideology could be collected by, for example, surveying users, imputing ideology based on user behavior, or joining data to the voter file. Each of these methods have advantages and potential challenges.\nUsing surveys in future work would allow researchers to collect data on ideology in a way that can facilitate comparisons with much of the extant literature in political science, and allow researchers to sample from a less politically engaged population. Of course, this could be tricky …","date":1429833600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1429833600,"objectID":"0f268982a57d085d401a76516f7bd169","permalink":"https://solmessing.netlify.app/post/exposure-to-ideologically-diverse-response/","publishdate":"2015-04-24T00:00:00Z","relpermalink":"/post/exposure-to-ideologically-diverse-response/","section":"post","summary":"Earlier this month, we published an early access version of our paper in ScienceExpress (Bakshy et al. 2015), “Exposure to ideologically diverse news and opinion on Facebook.” The paper constitutes the first attempt to quantify the extent to which ideologically cross-cutting hard news and opinion is shared by friends, appears in algorithmically ranked News Feeds, and is actually consumed (i.e., click through to read).\n","tags":[],"title":"Ideologically diverse news, an agenda for future research","type":"post"},{"authors":["Eytan Bakshy","Solomon Messing","Lada A Adamic"],"categories":null,"content":" Review by David Lazer Supplementary materials Replication materials Media: New York Times, the Washington Post, the BBC, CBS, Huffington Post, Ars Technica, Wired UK, The Verge. ","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"dfefb9c37ee61844bf84fb56d900fc37","permalink":"https://solmessing.netlify.app/publication/bakshy-2015-exposure/","publishdate":"2020-06-02T02:04:47.463109Z","relpermalink":"/publication/bakshy-2015-exposure/","section":"publication","summary":"Exposure to news, opinion, and civic information increasingly occurs through social media. How do these online networks influence exposure to perspectives that cut across ideological lines? Using deidentified data, we examined how 10.1 million U.S. Facebook users interact with socially shared news. We directly measured ideological homophily in friend networks and examined the extent to which heterogeneous friends could potentially expose individuals to cross-cutting content. We then quantified the extent to which individuals encounter comparatively more or less diverse content while interacting via Facebook's algorithmically ranked News Feed and further studied users' choices to click through to ideologically discordant content. Compared with algorithmic ranking, individuals' choices played a stronger role in limiting exposure to cross-cutting content.","tags":null,"title":"Exposure to ideologically diverse news and opinion on Facebook","type":"publication"},{"authors":["Robert Bond","Solomon Messing"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"51912c6b9fbd8ba45a049856aa55aa80","permalink":"https://solmessing.netlify.app/publication/bond-2015-quantifying/","publishdate":"2020-06-02T02:04:47.462374Z","relpermalink":"/publication/bond-2015-quantifying/","section":"publication","summary":"We demonstrate that social media data represent a useful resource for testing models of legislative and individual-level political behavior and attitudes. First, we develop a model to estimate the ideology of politicians and their supporters using social media data on individual citizens' endorsements of political figures. Our measure allows us to place politicians and more than 6 million citizens who are active in social media on the same metric. We validate the ideological estimates that result from the scaling process by showing they correlate highly with existing measures of ideology from Congress, and with individual-level self-reported political views. Finally, we use these measures to study the relationship between ideology and age, social relationships and ideology, and the relationship between friend ideology and turnout.","tags":null,"title":"Quantifying social media's political space: Estimating ideology from publicly revealed preferences on Facebook","type":"publication"},{"authors":["Sol Messing"],"categories":[],"content":"Yesterday a few of us on Facebook’s Data Science Team released a blogpost showing how candidates are campaigning on Facebook in the 2014 U.S. midterm elections. It was picked up in the Washington Post, in which Reid Wilson calls us \u0026#34;data wizards.\u0026#34; Outstanding.\nI used Hadly Wickham\u0026#39;s ggplot2 for every visualization in the post except a map that Arjun Wilkins produced using D3, and for the first time I used stacked bar charts. Now as I\u0026#39;ve stated previously, one should generally avoid bar charts, and especially stacked bar charts, except in a few specific circumstances.\nBut let\u0026#39;s talk about when not to use stacked bar charts first---I had the pleasure of chatting with Kaiser Fung of JunkCharts fame the other day, and I think what makes his site so compelling is the mix of schadenfreude and Fremdscham that makes taking apart someone else\u0026#39;s mistake such an effective teaching strategy and such a memorable read. I also appreciate the subtle nod to junk art.\nHere\u0026#39;s a typical, terrible stacked bar chart, which I found on http://www.storytellingwithdata.com/ and originally published on a Wall Street Journal blogpost. It shows the share of the personal computing device market by operating system, over time. The problem with using a stacked bar chart is that there are only two common baselines for comparison (the top and bottom of the plotting area), but we are interested in the relative share for more than two OS brands. The post is really concerned with Microsoft, so one solution would be to plot Microsoft versus the rest, or perhaps Microsoft on top versus Apple on the bottom with \u0026#34;Other\u0026#34; in the middle. Then we\u0026#39;d be able to compare the over time market share for Apple and Microsoft. As the author points out, an over time trend can also be visualized with line plots.\nBy far the worst offender I found in my 5 minute Google search was from junkcharts and originally published on Vox. These cumulative sum plots are so bad I was surprised to see them still up. The first problem is that the plots represent an attempt to convey way too much information---either plot total sales or pick a few key brands that are most interesting and plot them on a multi-line chart or set of faceted time series plots. The only brand for which you can quickly get a sense of sales over time is the Chevy Volt because it\u0026#39;s on the baseline. I\u0026#39;m sure the authors wanted to also convey the proportion of sales each year, but if you want to do that just plot the relative sales. Of course, the order in which the bars appear on the plot has no organizing principle, and you need to constantly move your eyes back and forth from the legend to the plot when trying to make sense of this monstrosity.\nAs Kaiser notes in his post, less is often more. Here\u0026#39;s his redux, which uses lines and aggregates by both quarter and brand, resulting in a far superior visualization:\nSo when *should* you use a stacked bar chart? Here are a two scenarios with examples, inspired by work with Eytan Bakshy and conversations with Ta Chiraphadhanakul and John Myles White.\n1. You care about comparing the proportion of two things, in this case the share of posts by Democrats and Republicans, along a variety of dimensions. In this case those dimensions consist of keyword (dictionary-based) categories (above) and LDA topics (below). When these are sorted by relative proportion, the reader gains insight into which campaign strategies and issues are used more by Republican or Democratic candidates.\nYou care about comparing proportions along an ordinal, additive variable such as 5-point party identification, along a set of dimensions. I provide an example from a forthcoming paper below (I\u0026#39;ll re-insert the axis labels once it\u0026#39;s published). Notice that it draws the reader toward two sets of comparisons across dimensions -- one for strong democrats and republicans, the other for the set of *all* Democrats and *all* Republicans. Of course, R code to produce these plots follows:\n# Uncomment these lines and install if necessary: #install.packages(\u0026#39;ggplot2\u0026#39;) #install.packages(\u0026#39;dplyr\u0026#39;) #install.packages(\u0026#39;scales\u0026#39;) library(ggplot2) library(dplyr) library(scales) # We start with the raw number of posts for each party for # each candidate. Then we compute the total by party and # category. catsByParty %\u0026gt;% group_by(party, all_cats) %\u0026gt;% summarise(tot = summ(posts)) # Next, compute the proportion by party for each category # using dplyr::mutate catsByParty \u0026lt;- catsByParty %\u0026gt;% group_by(all_cats) %\u0026gt;% mutate(prop = tot/sum(tot)) # Now compute the difference by category and order the # categories by that difference: catsByParty \u0026lt;- catsByParty %\u0026gt;% group_by(all_cats) %\u0026gt;% mutate(pdiff = diff(prop)) catsByParty$all_cats \u0026lt;- reorder(catsByParty$all_cats, -catsByParty$pdiff) # And plot: ggplot(catsByParty, aes(x=all_cats, y=prop, fill=party)) + scale_y_continuous(labels = percent_format()) + geom_bar(stat=\u0026#39;identity\u0026#39;) + geom_hline(yintercept=.5, linetype = \u0026#39;dashed\u0026#39;) + coord_flip() + theme_bw() + …","date":1412985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446336000,"objectID":"5d94250278351913449ae273f52e0d18","permalink":"https://solmessing.netlify.app/post/when-to-use-stacked-barcharts/","publishdate":"2014-10-11T00:00:00Z","relpermalink":"/post/when-to-use-stacked-barcharts/","section":"post","summary":"Yesterday a few of us on Facebook’s Data Science Team released a blogpost showing how candidates are campaigning on Facebook in the 2014 U.S. midterm elections. It was picked up in the Washington Post, in which Reid Wilson calls us \"data wizards.\" Outstanding.\n","tags":[],"title":"When to Use Stacked Barcharts?","type":"post"},{"authors":["Solomon Messing","Sean J Westwood"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"7e2c39141cb5dd16b90abe4c28649059","permalink":"https://solmessing.netlify.app/publication/messing-2014-selective/","publishdate":"2020-06-02T02:04:47.454746Z","relpermalink":"/publication/messing-2014-selective/","section":"publication","summary":"Much of the literature on polarization and selective exposure presumes that the internet exacerbates the fragmentation of the media and the citizenry. Yet this ignores how the widespread use of social media changes news consumption. Social media provide readers a choice of stories from different sources that come recommended from politically heterogeneous individuals, in a context that emphasizes social value over partisan affiliation. Building on existing models of news selectivity to emphasize information utility, we hypothesize that social media's distinctive feature, social endorsements, trigger several decision heuristics that suggest utility. In two experiments, we demonstrate that stronger social endorsements increase the probability that people select content and that their presence reduces partisan selective exposure to levels indistinguishable from chance.","tags":null,"title":"Selective exposure in the age of social media: Endorsements trump partisan source affiliation when selecting news online","type":"publication"},{"authors":["Justin Grimmer","Sean J. Westwood","Solomon Messing"],"categories":null,"content":" Media: Mischiefs of Faction. ","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"5d2a8978877a76495e40d836d45689cf","permalink":"https://solmessing.netlify.app/publication/gri-mes-wes-14/","publishdate":"2020-06-02T02:04:47.469664Z","relpermalink":"/publication/gri-mes-wes-14/","section":"publication","summary":"Constituents often fail to hold their representatives accountable for federal spending decisions―even though those very choices have a pervasive influence on American life. Why does this happen? Breaking new ground in the study of representation, The Impression of Influence demonstrates how legislators skillfully inform constituents with strategic communication and how this facilitates or undermines accountability. Using a massive collection of Congressional texts and innovative experiments and methods, the book shows how legislators create an impression of influence through credit claiming messages.  Anticipating constituents' reactions, legislators claim credit for programs that elicit a positive response, making constituents believe their legislator is effectively representing their district. This spurs legislators to create and defend projects popular with their constituents. Yet legislators claim credit for much more―they announce projects long before they begin, deceptively imply they deserve credit for expenditures they had little role in securing, and boast about minuscule projects. Unfortunately, legislators get away with seeking credit broadly because constituents evaluate the actions that are reported, rather than the size of the expenditures.  The Impression of Influence raises critical questions about how citizens hold their political representatives accountable and when deception is allowable in a democracy.","tags":null,"title":"The Impression of Influence: Legislator Communication, Representation, and Democratic Accountability","type":"publication"},{"authors":["Shanto Iyengar","Simon Jackman","Solomon Messing","Nicholas Valentino","Toril Aalberg","Raymond Duch","Kyu S Hahn","Stuart Soroka","Allison Harell","Tetsuro Kobayashi"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"2c65df7390dcb0c75e09462a9dbbe837","permalink":"https://solmessing.netlify.app/publication/iyengar-2013-attitudes/","publishdate":"2020-06-02T02:04:47.461571Z","relpermalink":"/publication/iyengar-2013-attitudes/","section":"publication","summary":"This paper demonstrates that citizens in seven advanced industrialized democracies generally oppose more open immigration policies, but stand ready to admit individual immigrants. Using an experimental design, we demonstrate the applicability of the ``person-positivity bias'' to immigration and investigate the effects of economic and cultural ``deservingness'' on evaluations of individual immigrants. Our results show that immigrants from professional backgrounds elicit higher levels of support than unskilled workers. The bias against unskilled workers is enlarged among immigrants accompanied by families. In comparison with occupational status and the number of family dependents, the target immigrant's cultural attributes---as measured by Middle Eastern nationality and Afrocentric appearance---prove relatively inconsequential as criteria for evaluating immigrants.","tags":null,"title":"Do attitudes about immigration predict willingness to admit individual immigrants? A cross-national test of the person-positivity bias","type":"publication"},{"authors":["Qiaoyun Shi","Laura J Pisani","Yauk K Lee","Solomon Messing","Celina Ansari","Srabani Bhaumik","Lisa Lowery","Brian D Lee","Dan E Meyer","Heike E Daldrup-Link"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"3b02c1428b9d7eb21419f6aea57c1661","permalink":"https://solmessing.netlify.app/publication/shi-2013-evaluation/","publishdate":"2020-06-02T02:04:47.456258Z","relpermalink":"/publication/shi-2013-evaluation/","section":"publication","summary":"Tumor-associated macrophages (TAM) maintain a chronic inflammation in cancers, which is associated with tumor aggressiveness and poor prognosis. The purpose of this study was to: (1) evaluate the pharmacokinetics and tolerability of the novel ultrasmall superparamagnetic iron oxide nanoparticle (USPIO) compound GEH121333; (2) assess whether GEH121333 can serve as a MR imaging biomarker for TAM; and (3) compare tumor MR enhancement profiles between GEH121333 and ferumoxytol. Blood half-lives of GEH121333 and ferumoxytol were measured by relaxometry (n = 4 each). Tolerance was assessed in healthy rats injected with high dose GEH121333, vehicle or saline (n = 4 each). Animals were monitored for 7 days regarding body weight, complete blood counts and serum chemistry, followed by histological evaluation of visceral organs. MR imaging was performed on mice harboring MMTV-PyMT-derived breast adenocarcinomas using a 7 T scanner before and up to 72 h post-injection (p.i.) of GEH121333 (n = 10) or ferumoxytol (n = 9). Tumor R1, R2* relaxation rates were compared between different experimental groups and time points, using a linear mixed effects model with a random effect for each animal. MR data were correlated with histopathology. GEH121333 showed a longer circulation half-life than ferumoxytol. Intravenous GEH121333 did not produce significant adverse effects in rats. All tumors demonstrated significant enhancement on T1, T2 and T2*-weighted images at 1, 24, 48 and 72 h p.i. GEH121333 generated stronger tumor T2* enhancement than ferumoxytol. Histological analysis verified intracellular compartmentalization of GEH121333 by TAM at 24, 48 and 72 h p.i. MR imaging with GEH121333 nanoparticles represents a novel biomarker for TAM assessment. This new USPIO MR contrast agent provides a longer blood half-life and better TAM enhancement compared with the iron supplement ferumoxytol. ","tags":null,"title":"Evaluation of the novel USPIO GEH121333 for MR imaging of cancer immune responses","type":"publication"},{"authors":["Aman Khurana","Hossein Nejadnik","Fanny Chapelin","Olga Lenkov","Rakhee Gawande","Sungmin Lee","Sandeep N Gupta","Nooshin Aflakian","Nikita Derugin","Solomon Messing"," others"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"19fc4256a404029410428d5fbb9e5732","permalink":"https://solmessing.netlify.app/publication/khurana-2013-ferumoxytol/","publishdate":"2020-06-02T02:04:47.457093Z","relpermalink":"/publication/khurana-2013-ferumoxytol/","section":"publication","summary":"Aim To develop a clinically applicable MRI technique for tracking stem cells in matrix-associated stem-cell implants, using the US FDA-approved iron supplement ferumoxytol. Materials \u0026 methods Ferumoxytol-labeling of adipose-derived stem cells (ADSCs) was optimized in vitro. A total of 11 rats with osteochondral defects of both femurs were implanted with ferumoxytol- or ferumoxides-labeled or unlabeled ADSCs, and underwent MRI up to 4 weeks post matrix-associated stem-cell implant. The signal-to-noise ratio of different matrix-associated stem-cell implant was compared with t-tests and correlated with histopathology. Results An incubation concentration of 500 µg iron/ml ferumoxytol and 10 µg/ml protamine sulfate led to significant cellular iron uptake, T2 signal effects and unimpaired ADSC viability. In vivo, ferumoxytol-and ferumoxides-labeled ADSCs demonstrated significantly lower signal-to-noise ratio values compared with unlabeled controls (p \u003c 0.01). Histopathology confirmed engraftment of labeled ADSCs, with slow dilution of the iron label over time. Conclusion Ferumoxytol can be used for in vivo tracking of stem cells with MRI. ","tags":null,"title":"Ferumoxytol: a new, clinically applicable label for stem-cell tracking in arthritic joints with MRI","type":"publication"},{"authors":["Solomon Messing"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"f2785b86c361b56c54719cba9be71ffd","permalink":"https://solmessing.netlify.app/publication/messing-2013-friends/","publishdate":"2020-06-02T02:04:47.464876Z","relpermalink":"/publication/messing-2013-friends/","section":"publication","summary":"This chapter describes the first known research on how socially-shared news affects political interest, policy preferences, and self reported voter turnout. It relies on a feed-ranking AB test on Facebook during the 2012 election to instrument exposure to content, and a large survey launched after election day. The chapter first examines the correlation between exposure to socially-shared public affairs content, or ``hard news,'' and civic engagement, in the setting of social media. It then analyzes the effect of the feed-ranking AB test, finding the following small but notable effects---additional exposure to socially shared political content caused small increases in self reported turnout, and caused respondents to report slightly more liberal policy preferences, particularly among independents.","tags":null,"title":"Friends that Matter: How Social News Shapes Political Knowledge, Attitudes, and Behavior","type":"publication"},{"authors":["Aman Khurana","Fanny Chapelin","Graham Beck","Olga D Lenkov","Jessica Donig","Hossein Nejadnik","Solomon Messing","Nikita Derugin","Ray Chun-Fai Chan","Amitabh Gaur"," others"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"020aeabe16a9cfe66314a5ff6ce4bc4f","permalink":"https://solmessing.netlify.app/publication/khurana-2013-iron/","publishdate":"2020-06-02T02:04:47.460841Z","relpermalink":"/publication/khurana-2013-iron/","section":"publication","summary":"In vivo--labeled MSCs demonstrated significantly higher ferumoxytol uptake compared with ex vivo--labeled cells. With electron microscopy, iron oxide nanoparticles were localized in secondary lysosomes. In vivo--labeled cells demonstrated significant T2 shortening effects in vitro and in vivo when they were compared with unlabeled control cells (T2 in vivo, 15.4 vs 24.4 msec; P \u003c .05) and could be tracked in osteochondral defects for 4 weeks. Histologic examination confirmed the presence of iron in labeled transplants and defect remodeling. Conclusion: Intravenous ferumoxytol can be used to effectively label MSCs in vivo and can be used for tracking of stem cell transplants with MR imaging. This method eliminates risks of contamination and biologic alteration of MSCs associated with ex vivo--labeling procedures.","tags":null,"title":"Iron administration before stem cell harvest enables MR imaging tracking after transplantation","type":"publication"},{"authors":["Rakhee S Gawande","Gabriel Gonzalez","Solomon Messing","Aman Khurana","Heike E Daldrup-Link"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"e977e8a49de19194f8129472a8c6f88c","permalink":"https://solmessing.netlify.app/publication/gawande-2013-role/","publishdate":"2020-06-02T02:04:47.458138Z","relpermalink":"/publication/gawande-2013-role/","section":"publication","summary":"We retrospectively analyzed DWI scans of 68 consecutive children with 39 benign and 34 malignant abdominal masses. To calculate the apparent diffusion coefficient (ADC) maps and ADC values, we used 1.5-T sequences at TR/TE/b-value of 5,250--7,500/54--64/b = 0, 500 and 3-T sequences at 3,500--4,000/66--73/b = 0, 500, 800. ADC values were compared between benign and malignant and between data derived at 1.5 tesla (T) and at 3 tesla magnetic field strength, using the Mann-Whitney-Wilcoxon test, ANOVA and a receiver operating curve (ROC) analysis.  Results There was no significant difference in ADC values obtained at 1.5 T and 3 T (P = 0.962). Mean ADC values (× 10−3 mm2/s) were 1.07 for solid malignant tumors, 1.6 for solid benign tumors, 2.9 for necrotic portions of malignant tumors and 3.1 for cystic benign lesions. The differences between malignant and benign solid tumors were statistically significant (P = 0.000025). ROC analysis revealed an optimal cut-off ADC value for differentiating malignant and benign solid tumors as 1.29 with excellent inter-observer reliability (alpha score 0.88).  Conclusion DWI scans and ADC values can contribute to distinguishing between benign and malignant pediatric abdominal tumors. ","tags":null,"title":"Role of diffusion-weighted imaging in differentiating benign and malignant pediatric abdominal tumors","type":"publication"},{"authors":[],"categories":[],"content":"After my post on making dotplots with concise code using plyr and ggplot, I got an email from my dad who practices immigration law and runs a website with a variety of immigration resources and tools. He pointed out that the post was written for folks who already know that they want to make dot plots, and who already know about bootstrapped standard errors. That’s not many people.\nIn an attempt to appeal to a broader audience, I’m starting a series in which I’ll outline the key principles I use when developing a visualization. In this post, I’ll articulate these principles, which combine some of Tuft’s aesthetic guidelines with Cleveland’s scientific approach to visualization, which is based on the psychological processes involved in making sense of visualizations, and has been rigorously tested via randomized controlled experiments. Based on these principles, I’ll argue that dotplots and scatterplots are better than other types of plots (especially pie charts) in most situations. In later posts, I’ll demonstrate another innovation whose widespread use I’ll credit to Cleveland and Tufte: the use of multiple panels (aka small multiples, trellis graphics, facets, generalized draftsman’s displays, multivar charts) to clearly convey the same information embedded in more complex and difficult to read visualizations, including multiple line plots and mosaic plots. In future posts I’ll also emphasize why it is important to provide some indication of the noise present in the underlying data using error bars or bands. Along the way, I’ll put you to the test–I’ll present some visualizations of the same data using different visualization techniques and ask you to try to get as much information as you can in 2 seconds from each type of visualization.\nA good visualization conveys key information to those who may have trouble interpreting numbers and/or statistics, which can make your findings accessible to a wider audience (more on this below). Visualizations also give your audience a break from lexical processing, which is especially useful when you are presenting your findings–people can listen to you and process the findings from a well-designed visual at the same time, but most people have trouble listening while reading your PowerPoint bullet points. Visualizations also convey key information embedded in massive amounts of data, which can aid your own exploratory analysis of data, no matter how massive.\nYet most visualizations are flawed, drawn using elements that make it unnecessarily difficult for the human visual system to make sense of things. I see a lot of these visualizations attending research presentations, screening incoming draft manuscripts as the assistant editor for Political Communication, and as a consumer of media info-graphics (CNN is especially bad, have a look at this monstrosity). Kevin Fox has an especially compelling visual speaking to this here. A big part of the problem is that Microsoft makes it easy to draw flashy but ultimately confusing visualizations in Excel. If you are too busy to read this post in full, follow this short list of guidelines and you’ll be on your way to producing elegant visualizations that impose a minimal cognitive burden on your audience:\nNever represent something in 2 or worse yet 3 dimensions if it can be represented in one—NEVER use pie charts, 3-D pie charts, stacked bar charts, or 3-D bar charts.\nRemove as much chart junk as possible–unnecessary gridlines, shading, borders, etc.\nGive your audience a sense of the noise present in your data–draw error bars or confidence bands if you are plotting estimates.\nIf you want to plot multiple types of groups on a single outcome (the visual analog of cross-tabulations/marginals), use multi-paneled plots. These can also help if overploting looks too cluttered.\nAvoid mosaic plots. Instead use paneled histograms.\nDitch the legend if you can (you almost always can).\nThe rest of the content in this series emphasizes why it makes sense to follow these guidelines. In this post I’ll look at the first point in detail and touch on the sixth. These two guidelines are most relevant when you want to look at a quantitative variable (e.g., earnings, vote-share, temperature, etc.) across different qualitative groupings (e.g., industry segment, candidate, party, racial group, season, etc.). This is one of the most common visualization tasks in business, media, and social science, and for this task people often use pie charts and/or bar charts, and occasionally dot plots.\nThe science of graphical perception\nWhen most people think about visualization, they think first of Edward Tufte. Tufte emphasizes integrity to the data, showing relationships between phenomena, and above all else aesthetic minimalism. I appreciate his ruthless crusade against chart junk and pie charts (nice quote from Data without Borders). We share an affinity for multipanel plotting approaches, which he calls “small multiples,” (thanks to Rebecca Weiss for pointing …","date":1330819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488672000,"objectID":"ada9e4ddb3a338e86de34d9370723250","permalink":"https://solmessing.netlify.app/post/visualization-series-insight-from-cleveland-and-tufte-on-plotting-numeric-data-by-groups/","publishdate":"2012-03-04T00:00:00Z","relpermalink":"/post/visualization-series-insight-from-cleveland-and-tufte-on-plotting-numeric-data-by-groups/","section":"post","summary":"After my post on making dotplots with concise code using plyr and ggplot, I got an email from my dad who practices immigration law and runs a website with a variety of immigration resources and tools. He pointed out that the post was written for folks who already know that they want to make dot plots, and who already know about bootstrapped standard errors. That’s not many people.\n","tags":[],"title":"Insight From Cleveland And Tufte On Plotting Numeric Data By Groups","type":"post"},{"authors":["Sol Messing"],"categories":[],"content":"Data can often be usefully conceptualized in terms affiliations between people (or other key data entities). It might be useful analyze common group membership, common purchasing decisions, or common patterns of behavior. This post introduces bipartite/affiliation network data and provides R code to help you process and visualize this kind of data. I recently updated this for use with larger data sets, though I put it together a while back.\nPreliminaries Much of the material here is covered in the more comprehensive “Social Network Analysis Labs in R and SoNIA,” on which I collaborated with Dan McFarland, Sean Westwood and Mike Nowak. For a great online introduction to social network analysis see the online book Introduction to Social Network Methods by Robert Hanneman and Mark Riddle.\nBipartite/Affiliation Network Data A network can consist of different ‘classes’ of nodes. For example, a two-mode network might consist of people (the first mode) and groups in which they are members (the second mode). Another very common example of two-mode network data consists of users on a particular website who communicate in the same forum thread. Here’s a short example of this kind of data. Run this in R for yourself - just copy an paste into the command line or into a script and it will generate a dataframe that we can use for illustrative purposes:\ndf \u0026lt;- data.frame( person = c(\u0026#39;Sam\u0026#39;,\u0026#39;Sam\u0026#39;,\u0026#39;Sam\u0026#39;,\u0026#39;Greg\u0026#39;,\u0026#39;Tom\u0026#39;,\u0026#39;Tom\u0026#39;,\u0026#39;Tom\u0026#39;,\u0026#39;Mary\u0026#39;,\u0026#39;Mary\u0026#39;), group = c(\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;d\u0026#39;), stringsAsFactors = F) df person group 1 Sam a 2 Sam b 3 Sam c 4 Greg a 5 Tom b 6 Tom c 7 Tom d 8 Mary b 9 Mary d Fast, efficient two-mode to one-mode conversion in R Suppose we wish to analyze or visualize how the people are connected directly - that is, what if we want the network of people where a tie between two people is present if they are both members of the same group? We need to perform a two-mode to one-mode conversion.\nTo convert a two-mode incidence matrix to a one-mode adjacency matrix, one can simply multiply an incidence matrix by its transpose, which sum the common 1’s between rows. Recall that matrix multiplication entails multiplying the k-th entry of a row in the first matrix by the k-th entry of a column in the second matrix, then summing, such that the ij-th row-column entry in resulting matrix represents the dot-product of the i-th row of the first matrix and the j-th column of the second. In mathematical notation:\n$$ AB = \\left [ \\begin{array}{cc} a \u0026amp; b \\\\\\ c \u0026amp; d \\end{array} \\right ] \\left [ \\begin{array}{cc} e \u0026amp; f \\\\\\ g \u0026amp; h \\end{array} \\right ] = \\left [ \\begin{array}{cc} ae+bg \u0026amp; af+bh \\\\\\ ce+dg \u0026amp; cf+dh \\end{array} \\right ] $$\nNotice further that multiplying a matrix by its transpose yields the following:\n$$ \\begin{align} AA’ = \\left[ \\begin{array}{cc} a \u0026amp; b \\\\\\ c \u0026amp; d \\end{array} \\right] \\left[ \\begin{array}{cc} a \u0026amp; c \\\\\\ b \u0026amp; d \\end{array} \\right] = \\left[ \\begin{array}{cc} aa+bb \u0026amp; ac+bd \\\\\\ ca+db \u0026amp; cc+dd \\end{array} \\right] \\end{align} $$\nBecause our incidence matrix consists of 0’s and 1’s, the off-diagonal entries represent the total number of common columns, which is exactly what we wanted. We’ll use the %*% operator to tell R to do exactly this. Let’s take a look at a small example using toy data of people and groups to which they belong. We’ll coerce the data to an incidence matrix, then multiply the incidence matrix by its transpose to get the number of common groups between people.\nThis is easy to do using the matrix algebra functions included in R. But first, you need to restructure your (edgelist) network data as an incidence matrix. An incidence will record a 1 for row-column combinations where a tie is present and 0 otherwise. One easy way to do this in R is to use the table function and then coerce the table object to a matrix object:\nm \u0026lt;- table( df ) M \u0026lt;- as.matrix( m ) If you are using the network or sna packages, a network object be coerced via as.matrix(your-network); with the igraph package use get.adjacency(your-network).\nThis is great, but what about if we are working with a really large data set? Network data is almost always sparse—there are far more pairwise combinations of potential connections than actual observed connections. Hence, we’d actually prefer to keep the underlying data structured in edgelist format, but we’d also like access to R’s matrix algebra functionality.\nWe can get the best of both worlds using the Matrix library to construct a sparse triplet representation of a matrix. But we’d also like to avoid building the entire incidence matrix and just feed Matrix our edgelist directly, a point that came up in a recent conversation I had with Sean Taylor. We feed Matrix our ‘person’ column to index ‘i’ (rows in the new incidence matrix), our ‘group’ column to index j (columns in the new incidence matrix), and we repeat ‘1’ for the length of the edgelist to denote an incidence.\nlibrary(\u0026#39;Matrix\u0026#39;) A \u0026lt;- spMatrix(nrow=length(unique(df$person)), ncol=length(unique(df$group)), i = …","date":1330819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589241600,"objectID":"d65b13c16e4dbae2ab430dcb587674fd","permalink":"https://solmessing.netlify.app/post/working-with-bipartite-affiliation-network-data-in-r/","publishdate":"2012-03-04T00:00:00Z","relpermalink":"/post/working-with-bipartite-affiliation-network-data-in-r/","section":"post","summary":"Data can often be usefully conceptualized in terms affiliations between people (or other key data entities). It might be useful analyze common group membership, common purchasing decisions, or common patterns of behavior. This post introduces bipartite/affiliation network data and provides R code to help you process and visualize this kind of data. I recently updated this for use with larger data sets, though I put it together a while back.\n","tags":[],"title":"Working with Bipartite/Affiliation Network Data in R","type":"post"},{"authors":["Rakhee S Gawande","Aman Khurana","Solomon Messing","Dong Zhang","Rosalinda T Castañeda","Robert E Goldsby","Randall A Hawkins","Heike E Daldrup-Link"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"25f28c69be85af54f682a4a6a62c7dbd","permalink":"https://solmessing.netlify.app/publication/gawande-2012-differentiation/","publishdate":"2020-06-02T02:04:47.452805Z","relpermalink":"/publication/gawande-2012-differentiation/","section":"publication","summary":"","tags":null,"title":"Differentiation of Normal Thymus from Anterior Mediastinal Lymphoma and Lymphoma Recurrence at Pediatric PET/CT","type":"publication"},{"authors":["Rakhee S Gawande","Spencer Behr","Solomon Messing","Robert E Goldsby","Randall A Hawkins","Heike E Daldrup-Link"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"5a19add7da3fbf0f14499fc92ed65b79","permalink":"https://solmessing.netlify.app/publication/gawande-2012-fdg/","publishdate":"2020-06-02T02:04:47.459277Z","relpermalink":"/publication/gawande-2012-fdg/","section":"publication","summary":"","tags":null,"title":"FDG PET/CT for the Evaluation of Normal Thymus, Lymphoma Recurrence, and Mediastinal Lymphoma in Pediatric Patients Response","type":"publication"},{"authors":["Justin Grimmer","Solomon Messing","Sean J. Westwood"],"categories":null,"content":" Supplementary Information ","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"416a548a5447ed74020dacde412c4853","permalink":"https://solmessing.netlify.app/publication/grimmer-how-2012/","publishdate":"2020-06-02T02:04:47.468728Z","relpermalink":"/publication/grimmer-how-2012/","section":"publication","summary":"Particularistic spending, a large literature argues, builds support for incumbents. This literature equates money spent in the district with the credit constituents allocate. Yet, constituents lack the necessary information and motivation to allocate credit in this way. We use extensive observational and experimental evidence to show how legislators' credit claiming messages---and not just money spent in the district---affect how constituents allocate credit. Legislators use credit claiming messages to influence the expenditures they receive credit for and to affect how closely they are associated with spending in the district. Constituents are responsive to credit claiming messages---they build more support than other nonpartisan messages. But contrary to expectations from other studies, constituents are more responsive to the total number of messages sent rather than the amount claimed. Our results have broad implications for political representation, the personal vote, and the study of U.S. Congressional elections. ","tags":null,"title":"How Words and Money Cultivate a Personal Vote: The Effect of Legislator Credit Claiming on Constituent Credit Allocation","type":"publication"},{"authors":["Aman Khurana","Hossein Nejadnik","Rakhee Gawande","Guiting Lin","Sungmin Lee","Solomon Messing","Rosalinda Castaneda","Nikita Derugin","Laura Pisani","Tom F Lue"," others"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"786f2c7b23d09fe2c571bf4952ac25de","permalink":"https://solmessing.netlify.app/publication/khurana-2012-intravenous/","publishdate":"2020-06-02T02:04:47.453844Z","relpermalink":"/publication/khurana-2012-intravenous/","section":"publication","summary":"","tags":null,"title":"Intravenous ferumoxytol allows noninvasive MR imaging monitoring of macrophage migration into stem cell transplants","type":"publication"},{"authors":["Solomon Messing","Cameron Marlow","Eytan Bakshy"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"95bb892c20393a8ef472a05f1015ead8","permalink":"https://solmessing.netlify.app/publication/messing-2012-ts/","publishdate":"2020-06-02T02:04:47.470668Z","relpermalink":"/publication/messing-2012-ts/","section":"publication","summary":"","tags":null,"title":"The 2012 Election Day Through the Facebook Lens","type":"publication"},{"authors":["Toril Aalberg","Shanto Iyengar","Solomon Messing"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"57ed5bd2b494f1e506e83c36712449eb","permalink":"https://solmessing.netlify.app/publication/aalberg-2012-deserving/","publishdate":"2020-06-02T02:04:47.451855Z","relpermalink":"/publication/aalberg-2012-deserving/","section":"publication","summary":"","tags":null,"title":"Who is a `deserving'immigrant? An experimental study of Norwegian attitudes","type":"publication"},{"authors":["Solomon Messing"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"0576dc9e0f87910bd26d4c6e59f06c0d","permalink":"https://solmessing.netlify.app/publication/messing-2011-measuring/","publishdate":"2020-06-02T02:04:47.450255Z","relpermalink":"/publication/messing-2011-measuring/","section":"publication","summary":"","tags":null,"title":"Measuring issue salience: Using supervised machine learning to generate data from free responses to the 'most important problem' question","type":"publication"},{"authors":["Letitia Lew","Truc Nguyen","Solomon Messing","Sean Westwood"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"fae5010841580654746a3dacd80a79c2","permalink":"https://solmessing.netlify.app/publication/lew-2011-course/","publishdate":"2020-06-02T02:04:47.4509Z","relpermalink":"/publication/lew-2011-course/","section":"publication","summary":"","tags":null,"title":"Of course I wouldn't do that in real life: advancing the arguments for increasing realism in HCI experiments","type":"publication"},{"authors":["Shanto Iyengar","Kyu S Hahn","Solomon Messing","Jeremy N Bailenson"],"categories":null,"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199145600,"objectID":"b9250434eff1e09336ecd546de2c2f4f","permalink":"https://solmessing.netlify.app/publication/iyengar-2008-explicit/","publishdate":"2020-06-02T02:04:47.449595Z","relpermalink":"/publication/iyengar-2008-explicit/","section":"publication","summary":"Skin color is an explicit racial cue. Although there is strong evidence linking darker skin complexion to the activation of racial stereotypes and adverse societal outcomes, little is known about the extent to which this effect is in play during political campaigns. If white voters make use of this skin complexion cue, we would expect exposure to darker images of a minority candidate to result in a ``dark-skin penalty'' at the ballot box. We investigate the impact of skin complexion on support for Barack Obama at two different stages of the 2008 campaign: Study 1 occurred during the primary campaign and Study 2 during the closing stages of the general election. Our findings suggest that when citizens are still learning about a minority candidate's personal background, subtle changes in skin complexion can have an effect on evaluations of that candidate and that citizens with higher levels of implicit racial bias are less likely to prefer a darker-skinned minority candidate. ","tags":null,"title":"Do explicit racial cues influence candidate preference? The case of skin complexion in the 2008 campaign","type":"publication"},{"authors":null,"categories":null,"content":" SM is currently an employee of New York University. SM was previously an employee of Twitter and held a significant financial interest (SFI, defined as holding more than $5,000 in stock). SM’s employee equity was converted to cash following the conclusion of Twitter’s sale to Elon Musk. SM was against the company’s acquisition and asked to be included in the first round of layoffs. SM declined to accept severance compensation and did not sign the proposed severance agreement, which included a restrictive non-disparagement clause. SM was previously an employee of Facebook (now Meta) and at various points in time held a SFI in the company. SM sold all employee equity grants (RSUs) shortly after leaving the company in both 2015 and 2020. SM was previously an employee of Science Applications International Corporation and in the past held a SFI in the company. SM was previously an employee of Pew Research Center. SM was previously an employee of Acronym, including during the implementation of experiments designed to assess ad effectiveness. SM was previously a paid contractor for Morning Consult. SM has actively managed investments which may include SFIs in Apple, AMD, Alphabet (Google), Amazon, Intel, Meta, Microsoft, NVIDIA, Salesforce. SM has sometimes sold (ordinary) Facebook/Meta stock to avoid the appearance of a potential conflict of interest when conducting research relevant to the platform. SM has received scholarly funding from Google (now Alphabet). SM is an inventor on patents assigned to Twitter and Law-on-line. SM’s travel to or lodging at conferences has been supported by universities and past employers, including Pew Research Center (2015-2018), Facebook (2012-2020), Twitter (2021-2022). ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"05bad1587df1422d82c485a4081777fc","permalink":"https://solmessing.netlify.app/disclosures/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/disclosures/","section":"","summary":" SM is currently an employee of New York University. SM was previously an employee of Twitter and held a significant financial interest (SFI, defined as holding more than $5,000 in stock). SM’s employee equity was converted to cash following the conclusion of Twitter’s sale to Elon Musk. SM was against the company’s acquisition and asked to be included in the first round of layoffs. SM declined to accept severance compensation and did not sign the proposed severance agreement, which included a restrictive non-disparagement clause. SM was previously an employee of Facebook (now Meta) and at various points in time held a SFI in the company. SM sold all employee equity grants (RSUs) shortly after leaving the company in both 2015 and 2020. SM was previously an employee of Science Applications International Corporation and in the past held a SFI in the company. SM was previously an employee of Pew Research Center. SM was previously an employee of Acronym, including during the implementation of experiments designed to assess ad effectiveness. SM was previously a paid contractor for Morning Consult. SM has actively managed investments which may include SFIs in Apple, AMD, Alphabet (Google), Amazon, Intel, Meta, Microsoft, NVIDIA, Salesforce. SM has sometimes sold (ordinary) Facebook/Meta stock to avoid the appearance of a potential conflict of interest when conducting research relevant to the platform. SM has received scholarly funding from Google (now Alphabet). SM is an inventor on patents assigned to Twitter and Law-on-line. SM’s travel to or lodging at conferences has been supported by universities and past employers, including Pew Research Center (2015-2018), Facebook (2012-2020), Twitter (2021-2022). ","tags":null,"title":"Disclosures","type":"page"},{"authors":null,"categories":null,"content":"You need to dress approriately for mountainbiking/fat tire cycling in the colder temperatures of the upper midwest. Here’s what has worked for me after two winters outside of the Twin Cities in Minnesota:\n55-65: Normal gloves. Flats with light wool socks. MTB shorts (knee pads, elbow pads, body armor will add a bit of warmth). Alt: mtb pants and long sleeve undershirt. Full face helmet or skullcap.\n45-55: Heavy gloves. Flats, wool socks. MTB pants, long sleeve undershirt, short sleeve shirt, fleece mid layer. Removable vest or puffy jacket for nicer warmup. Full face helmet or skullcap, goggles optional.\n35-45: Warm gloves or bar mitts. Flats, wool socks, toe caps. MTB pants, long sleeve undershirt, fleece mid layer. Light shell w underarm zips. Full face or ski/snowboard helmet + goggles. heavy gloves.\n25-35: Bar mitts with MTB gloves. Five-Ten Impact Pro Mid (or warmer flat) + toe caps or winter cycling boots. Warm pants, long sleeve undershirt, fleece mid layer. Light shell w underarm zips. Full face with skullcap or ski/snowboard helmet. Goggles + neck warmer or face mask.\n15-25: Bar mitts with MTB or warm gloves. Five-Ten Impact Pro Mid (or warmer) + toe caps and foot warmers or 45 NRTH cycling boots. Warm or ski pants, long sleeve undershirt, fleece mid layer. Light shell w underarm zips. Ski/snowboard helmet, goggles, face mask.\nUnder 15: Bar mitts w/ warm gloves. 45 NRTH winter boots, consider toe warmers. Ski pants, long sleeve undershirt, fleece mid layer. Ski/snowboard outer layer w/ underarm zips. Ski/snowboard helmet, goggles, face mask.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"860fb8c9df128f24602149fb655df1d7","permalink":"https://solmessing.netlify.app/mtbgearweather/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/mtbgearweather/","section":"","summary":"You need to dress approriately for mountainbiking/fat tire cycling in the colder temperatures of the upper midwest. Here’s what has worked for me after two winters outside of the Twin Cities in Minnesota:\n","tags":null,"title":"MTB Gear","type":"page"},{"authors":null,"categories":null,"content":" Best terminal (iterm 2) setup I’ve found yet Fix annoying error messages in RStudio StatET, an R plugin for Eclipse. Why not just RStudio? StatET has the best object browser available if you’re doing anything with JSON or lists of lists, and will not crash when R crashes, unlike RStudio. It also plays well with cloud instances. Though, yes, I find myself using RStudio on new machines because setting up StatET can be a challenge. Get started using Hugo - Academic. Quickly snap windows side-by-side with shortcut keys on Mac using Rectangle. How to setup shotcut keys in gmail. Conda on Singularity (needed for NYU HPC) How to launch Singularity container remotely in VSCode ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d9ed7a09b8c4f6666f7fa92d4d10d00b","permalink":"https://solmessing.netlify.app/techsetup/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/techsetup/","section":"","summary":" Best terminal (iterm 2) setup I’ve found yet Fix annoying error messages in RStudio StatET, an R plugin for Eclipse. Why not just RStudio? StatET has the best object browser available if you’re doing anything with JSON or lists of lists, and will not crash when R crashes, unlike RStudio. It also plays well with cloud instances. Though, yes, I find myself using RStudio on new machines because setting up StatET can be a challenge. Get started using Hugo - Academic. Quickly snap windows side-by-side with shortcut keys on Mac using Rectangle. How to setup shotcut keys in gmail. Conda on Singularity (needed for NYU HPC) How to launch Singularity container remotely in VSCode ","tags":null,"title":"Tech Stack","type":"page"}]