<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: February 4, 2026 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.7" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.5adeb309104bf059bfce5194cee5d4d8.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  






<script async src="https://www.googletagmanager.com/gtag/js?id=G-9XTZZP2CJ8"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-9XTZZP2CJ8', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>
























  
  
  






  <meta name="author" content="Sol Messing" />





  

<meta name="description" content="Analysis of recent Science papers shows little evidence that Facebook&#39;s feed ranking increases ideological segregation or creates a meaningful &#39;Filter Bubble&#39; effect." />



<link rel="alternate" hreflang="en-us" href="https://solmessing.netlify.app/post/thoughts-on-election-2020/" />
<link rel="canonical" href="https://solmessing.netlify.app/post/thoughts-on-election-2020/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu_b6b141330a993e2f.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu_bdf5fe8f122b026c.png" />

<meta name="theme-color" content="#1565c0" />










  






<meta property="twitter:card" content="summary_large_image" />

  <meta property="twitter:site" content="@SolomonMg" />
  <meta property="twitter:creator" content="@SolomonMg" />
<meta property="twitter:image" content="https://solmessing.netlify.app/post/thoughts-on-election-2020/featured.jpeg" />



  

<meta property="og:type" content="article" />
<meta property="og:site_name" content="Sol Messing" />
<meta property="og:url" content="https://solmessing.netlify.app/post/thoughts-on-election-2020/" />
<meta property="og:title" content="Disaggregating &#39;Ideological Segregation&#39; | Sol Messing" />
<meta property="og:description" content="Analysis of recent Science papers shows little evidence that Facebook&#39;s feed ranking increases ideological segregation or creates a meaningful &#39;Filter Bubble&#39; effect." /><meta property="og:image" content="https://solmessing.netlify.app/post/thoughts-on-election-2020/featured.jpeg" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-08-02T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2023-08-02T00:00:00&#43;00:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://solmessing.netlify.app/post/thoughts-on-election-2020/"
  },
  "headline": "Disaggregating 'Ideological Segregation'",
  
  "image": [
    "https://solmessing.netlify.app/post/thoughts-on-election-2020/featured.jpeg"
  ],
  
  "datePublished": "2023-08-02T00:00:00Z",
  "dateModified": "2023-08-02T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Sol Messing"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Sol Messing",
    "logo": {
      "@type": "ImageObject",
      "url": "https://solmessing.netlify.app/media/icon_hu_3baeddb697bfad35.png"
    }
  },
  "description": "Analysis of recent Science papers shows little evidence that Facebook's feed ranking increases ideological segregation or creates a meaningful 'Filter Bubble' effect."
}
</script>

  

  




  
  
  

  
  

  


  
  <title>Disaggregating &#39;Ideological Segregation&#39; | Sol Messing</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="9d425fa8df98c1daeacd89a289b8834f" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.9e4214442a7711d35691acd58f6f6361.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Sol Messing</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Sol Messing</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#featured"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#media"><span>Media</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#mybio"><span>Bio</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/techsetup/"><span>Tech Stack</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/disclosures/"><span>Disclosures</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/pdf/CV/CV.pdf"><span>CV</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  






















  
  



<div class="article-container pt-3">
  <h1>Disaggregating &#39;Ideological Segregation&#39;</h1>

  
  <p class="page-subtitle">Domain-level analysis in a new <em>Science</em> paper greatly overstates the influence of algorithmic feed ranking on segregation, aka the &lsquo;Filter Bubble&rsquo;</p>
  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Sol Messing</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Aug 2, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    20 min read
  </span>
  

  
  
  
  

  
  

</div>

  





</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 402px;">
  <div style="position: relative">
    <img src="/post/thoughts-on-election-2020/featured_hu_eccf7be6675c4e49.webp" width="720" height="402" alt="" class="featured-image">
    <span class="article-header-caption">González-Bailón et al&rsquo;s figure 2C seems to show almost no Filter-Bubble effect.</span>
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <h3 id="tldr">TLDR:</h3>
<ol>
<li>[UPDATED SEPT 30] Yesterday, Science <a href="/pdf/science.adk1211.pdf">published a letter I wrote</a> arguing that there is little evidence of algorithmic bias in Facebook’s feed ranking system that would serve to increase ideological segregation, also known as <a href="https://books.google.com/books/about/The_Filter_Bubble.html?id=Qn2ZnjzCE3gC" target="_blank" rel="noopener">the &ldquo;Filter Bubble&rdquo; hypothesis</a>.</li>
<li>This contradicts claims in <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a> that Newsfeed ranking increases ideological segregation. This claim was the main piece of evidence in the Science <a href="https://www.science.org/toc/science/381/6656" target="_blank" rel="noopener">Special Issue on Meta</a> that might support the controversial cover that suggested that Meta’s algorithms are “Wired to Split.”</li>
<li>The issue is that while domain-level analysis suggests feed-ranking increases ideological segregation, URL-level analysis shows <em>no difference</em> in ideological segregation before and after feed-ranking.</li>
<li>And we should strongly prefer their URL-level analysis. Domain-level analysis <em>effectively mislabels highly partisan content</em> as &ldquo;moderate/mixed,&rdquo; especially on websites like YouTube, Reddit, and Twitter (<a href="https://ori.hhs.gov/education/products/niu_authorship/mistakes/09mistake-a.htm" target="_blank" rel="noopener">aggregation bias/ecological fallacy</a>).</li>
<li>Interestingly, the authors seem to agree&mdash;the discussion section points out problems with domain-level analysis.</li>
<li>Another <em>Science</em> paper from the same issue, <a href="https://www.science.org/doi/10.1126/science.abp9364" target="_blank" rel="noopener">Guess et al 2023</a> shows (in the SM) that Newsfeed ranking actually <em>decreases</em> exposure to <em>political content</em> from like-minded sources compared with reverse-chronological feedranking.</li>
<li>The evidence in the 4 recent papers is not consistent with a meaningful Filter Bubble effect in 2020; nor does it support the notion that Meta&rsquo;s algorithms are &ldquo;Wired to Split.&rdquo;</li>
<li>Furthermore, domain-level aggregation bias is a big issue in a great deal of past research on ideological segregation, because domain-level analysis <em>understates</em> media polarization. Because <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a> gives both URL- and domain-level estimates, we can see the magnitude of aggregation bias. It&rsquo;s huge.</li>
<li>I make a number of other observations about what we know about whether social media is polarizing and discuss implications for the controversial Science cover and Meta&rsquo;s flawed claims that this research is exculpatory.</li>
</ol>
<!-- 6. None of this is the last word on social media algorithms---as [González-Bailón et al 2023](https://www.science.org/doi/full/10.1126/science.ade7138) point out, we need additional research on friend/page/group/etc recommender systems, which may polarize the graph itself.  -->
<h3 id="introicymi">Intro/ICYMI</h3>
<details>
  <summary>Click to expand</summary>
<p>Last week saw the release of a series of <a href="https://www.science.org/toc/science/381/6656" target="_blank" rel="noopener">excellent papers in <em>Science</em></a>. I was particularly interested in <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a>, which measures &ldquo;ideological segregation.&rdquo; This concept is based on <a href="https://web.stanford.edu/~gentzkow/research/echo_chambers.pdf" target="_blank" rel="noopener">Matt Gentzkow and Jesse Shapiro&rsquo;s 2011 work</a>. As they note, &ldquo;The index ranges from 0 (all conservative and liberal visits are to the same outlet) to 1 (conservatives only visit 100% conservative outlets and liberals only visit 100% liberal outlets).&rdquo;</p>
<p>This paper also replicates and extends my own work with Eytan Bakshy and Lada Adamic, also published in <a href="https://solomonmg.github.io/pdf/Science-2015-Bakshy-1130-2.pdf" target="_blank" rel="noopener"><em>Science</em> in 2015</a>.</p>
<p>To be clear <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a> goes a lot further, examining how these factors vary over-time, investigating clusters of isolated partisan media organizations, and patterns in the consumption of misinformation. They find (1) ideological segregation is high; (2) ideological segregation “increases after algorithmic curation” consistent with the “Filter Bubble” hypothesis; (3) there is a substantial right wing “echo chamber” in which conservatives are essentially siloed from the rest of the site (4) where misinformation thrives.</p>
<p>I&rsquo;ve had many years to think about issues related to these questions, after working with similar data from 2012 in my dissertation, and co-authoring a <a href="https://solomonmg.github.io/pdf/Science-2015-Bakshy-1130-2.pdf" target="_blank" rel="noopener">Science paper</a> while working at Facebook using 2014 data. I also saw the design (but not results) presented at the <a href="https://www.ssrc.org/programs/digital-platforms-initiative/2023-ssrc-workshop-on-the-economics-of-social-media/" target="_blank" rel="noopener">2023 SSRC Workshop on the Economics of Social Media</a>, though I did not notice these issues until I saw the final paper.</p>
<p>I put together these thoughts after discussion and feedback from Dean Eckles and Tom Cunningham, former colleagues at Stanford, Facebook, and Twitter.</p>
<!-- [Click here to read the backstory on Echo Chambers, Filter Bubbles, and Selective Exposure, including where my own past work fits in](#a-brief-history-of-echo-chambers-filter-bubbles-and-selective-exposure) -->
</details>
<h3 id="a-brief-history-of-echo-chambers-filter-bubbles-and-selective-exposure">A Brief History of Echo Chambers, Filter Bubbles, and Selective Exposure</h3>
<details>
  <summary>Click to expand</summary>
<!-- 20 years ago I worked as a foreign media analyst and I noticed that a great deal of misinformation circulating in news websites in Indonesia and the Middle East came from Alex Jones' InfoWars (yes he's been around for a long time). I became fascinated with the question of how people get their media and how technology changes that.  -->
<p>The conventional academic wisdom when I started my PhD was that we shouldn&rsquo;t expect to see much in the way of media effects (<a href="https://books.google.com/books/about/The_Effects_of_Mass_Communication.html?id=CzcGAQAAIAAJ" target="_blank" rel="noopener">Klapper 1960</a>) because people tended to &ldquo;select into&rdquo; content that reinforced their views (<a href="https://www.jstor.org/stable/2747198" target="_blank" rel="noopener">Sears and Freedman 1967</a>).</p>
<p>In 2007, Cass Sunstein wrote <a href="https://www.jstor.org/stable/j.ctt7tbsw" target="_blank" rel="noopener">&ldquo;Republic.com 2.0&rdquo;</a>, which warned that the internet could allow us to even more easily isolate ourselves into &ldquo;information cocoons&rdquo; and &ldquo;echo chambers.&rdquo; Technology allows us to &ldquo;filter&rdquo; exactly what we want to see, and design our own programming. Cass also suggested this could lead to polarization.</p>
<!-- What's more, new media should be expected to further strengthen this "minimal effects" hypothesis ([Bennett and Iyengar 2008](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=a2fcebd37ba1e919f662a287841b0356603cd0a4)).  -->
<p>In 2009-2010, Sean Westwood and I ran a series of studies suggesting that <a href="https://journals.sagepub.com/doi/10.1177/0093650212466406" target="_blank" rel="noopener">popularity and social cues</a> in news aggregators and social media websites might be a way out of selective news consumption&mdash;we might be <em>more</em> exposed to cross-cutting views on platforms that feature a social component, and furthermore, this social component seemed to be more important that media &ldquo;source&rdquo; label. That was great in the abstract, but what happens on actual websites that people use?</p>
<p>The extent to which widely used social media platforms might allow us to exit &ldquo;echo chambers&rdquo; depended on the extent of cross-partisan friendships and interactions on platforms like Facebook. I did a PhD internship at Facebook to look into that, and the question of whether encountering <a href="https://www.dropbox.com/s/nu39148ukbab34r/CH7brief.pdf?raw=true" target="_blank" rel="noopener">political news on social media was ideologically polarizing</a> (note that the results are as not well powered as I would like). That work evolved into dissertation chapters and eventually our <a href="https://solomonmg.github.io/pdf/Science-2015-Bakshy-1130-2.pdf" target="_blank" rel="noopener">Science paper</a></p>
<p>Now <a href="https://en.wikipedia.org/wiki/Eli_Pariser" target="_blank" rel="noopener">Eli Parsner</a> had just published a book on &ldquo;<a href="https://books.google.com/books/about/The_Filter_Bubble.html?id=Qn2ZnjzCE3gC" target="_blank" rel="noopener">Filter Bubbles</a>&rdquo; suggesting that media technologies like Google Search and Facebook NewsFeed not only allowed us to ignore the &ldquo;other side,&rdquo; but actively filtering out search results and friends posts with perspectives from the other side.</p>
<p>What&rsquo;s more, a lot of people in the Human Computer Interaction (HCI) world were very interested in how one might examine this empirically, and I started collecting data with Eytan Bakshy that would do just that. The paper would allow us to quantify echo chambers created by our network of contacts, filter bubbles, and partisan selective exposure in social media by looking at exposure to <a href="https://www.jstor.org/stable/3117813" target="_blank" rel="noopener">ideologically &ldquo;cross-cutting&rdquo; content</a>.</p>
<p>We defined a few key components:</p>
<p><strong>Random</strong> - The set of content (external URLs) shared on Facebook writ large.</p>
<p><strong>Potential</strong> - The set of content shared by one&rsquo;s friends</p>
<p><strong>Exposed</strong> - The set of content appearing in one&rsquo;s Newsfeed.</p>
<p><strong>Selected</strong> - The set of content one clicks on.</p>
<p><strong>Endorsed</strong> - The set of content one &rsquo;likes'.</p>
<p>















<figure  id="figure-figure-6-from-messing-2013-our-original-analysis-of-the-distribution-of-ideologically-aligned-content-on-facebook-using-data-from-2012">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/Ch6Fig6.5.jpg" alt="Figure 6 from Messing 2013: Our original analysis of the distribution of ideologically-aligned content on Facebook using data from 2012." loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure 6 from Messing 2013: Our original analysis of the distribution of ideologically-aligned content on Facebook using data from 2012.
    </figcaption></figure>
</p>
<p>















<figure  id="figure-figure-3b-from-bakshy-et-al-2015-data-from-2014-quantifying-cross-cutting-content-on-facebook">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/ScienceBakshyFig3B.jpg" alt="Figure 3B from Bakshy et al 2015: Data from 2014 quantifying cross-cutting content on Facebook." loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure 3B from Bakshy et al 2015: Data from 2014 quantifying cross-cutting content on Facebook.
    </figcaption></figure>
</p>
<p>Unlike when I started to study social media in 2009 and no one was interested, in 2014, people understood that social media was an important force that was reshaping at least media if not society more broadly. And Science was particularly interested in the role of algorithms played in this environment.</p>
<p>We published our results in <a href="https://solomonmg.github.io/pdf/Science-2015-Bakshy-1130-2.pdf" target="_blank" rel="noopener">Science</a>, and the response from many was &ldquo;well this is smaller than expected,&rdquo; including a piece in <em>Wired</em> from <a href="https://www.wired.com/2015/05/did-facebooks-big-study-kill-my-filter-bubble-thesis/" target="_blank" rel="noopener">Eli Parisner himself</a>. David Lazer, one of the lead authors of <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a>, also <a href="https://education.biu.ac.il/sites/education/files/shared/science-2015-lazer-1090-1.pdf" target="_blank" rel="noopener">wrote a perspective in <em>Science</em></a>.</p>
<p>However, the piece immediately drew a great deal of criticism. This is in part because I wrote that exposure was driven more by individual choices than algorithms, which ignored the potential influence of friend recommendation systems and, more broadly, swept aside the extent to which interfaces structure interactions on websites, which my own dissertation work had shown was quite substantial.</p>
<p>The study also had important limitations, many of which I addressed in a post suggesting how <a href="https://solomonmg.github.io/post/exposure-to-ideologically-diverse-response/" target="_blank" rel="noopener">future work could provide a more robust picture</a>.</p>
<p>I was (much later) tech lead for Social Science One (2018-2020), which gave external researchers access to data (the <a href="/pdf/Facebook_DP_URLs_Dataset.pdf">&lsquo;Condor&rsquo; URLs data set</a>) via differential privacy. My goal was to enable the kind of work research done <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a>. However, it soon became clear that Social Science One&rsquo;s data sharing model and differential privacy in particular was not suitable for ground-breaking research.</p>
<p>I personally advocated (with Facebook Researcher and longtime colleague <a href="https://twitter.com/anniefranco" target="_blank" rel="noopener">Annie Franco</a>) for the collaboration model used in the Election 2020 project, wherein external researchers would collaborate with Facebook researchers. That model would have to shield the research from any interference from Facebook&rsquo;s Communications and Policy arm, which might attempt to interfere with the inturpretation or publication of any resulting papers, which would create ethical conflicts.</p>
<p>I advocated for pre-registration to accomplish this, not merely to ensure scientific rigor but to protect against conflicts of interest and selective reporting of results. However, I left Facebook in January of 2020 and have not been deeply involved in the project since.</p>
<p><a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a> does in fact accomplish most if not all of what I recommended future research do and goes much further than our original study, and the authors should be applauded for it. The paper shows that on Facebook (1) ideological segregation is high (in fact it&rsquo;s arguably higher than implied in the paper); (2) there is a substantial right wing &ldquo;echo chamber&rdquo; in which conservatives are siloed from the rest of the site (3) where misinformation thrives. When they start to talk about the filter bubble though, things get more complicated.</p>
</details>
<h3 id="is-there-a-filter-bubble-on-facebook">Is there a Filter Bubble on Facebook</h3>
<p>Are Facebook&rsquo;s algorithms &ldquo;Wired to split&rdquo; the public? This question is at the core of the recent <em>Science</em> issue, it&rsquo;s hotly debated in the field of algorithmic bias. A suspicion that the answer is &ldquo;yes&rdquo; has motivated a number of policy and regulatory actions. Armed with unprecendented data, <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a> seeks to answer this and other related questions.</p>
<p>There are three relevant claims that answer this question in the text: (1) &ldquo;ideological segregation is high and increases as we shift from potential exposure to actual exposure to engagement&rdquo; in the abstract, (2) &ldquo;The algorithmic promotion of compatible content from this inventory is positively associated with an increase in the observed segregation as we move from potential to exposed audiences&rdquo; in the discussion section, and (3) &ldquo;Segregation scores drawn from exposed audiences are higher than those based on potential audiences &hellip; (the difference between potential and engaged audiences is only visible at the domain level),&rdquo; in the caption of Figure 2.</p>
<p>These statements are generally confirmatory of algorithmic segregation, aka the <a href="https://books.google.com/books/about/The_Filter_Bubble.html?id=Qn2ZnjzCE3gC" target="_blank" rel="noopener">Filter Bubble hypothesis</a>.</p>
<p>But look at Figure 2, on which these claims seem to be based. Figure 2B shows an increase in observed segregation as you move from potential to exposed audiences. BUT Figure 2C&mdash;describing the same phenomena&mdash;does <em>not</em> (as noted in the caption).</p>
<p>















<figure  id="figure-when-viewed-at-the-level-of-the-url-2c-the-study-is-consistent-with-a-negligible-filter-bubble-effect">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/BailonFig2BC.jpeg" alt="Figure 2 (B &amp; C) from González-Bailón et al 2023: When viewed at the level of the URL (2C), the study is consistent with a negligible Filter Bubble effect" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      When viewed at the level of the URL (2C), the study is consistent with a negligible Filter Bubble effect
    </figcaption></figure>
</p>
<h3 id="so-which-is-it">So which is it?</h3>
<p>First, what&rsquo;s the difference between these two figures? 2B aggregates things at the domain level (e.g., <a href="https://www.yahoo.com" target="_blank" rel="noopener">www.yahoo.com</a>) while 2C aggregates things at the URL level (e.g., <a href="https://www.yahoo.com/news/pence-trumps-indictment-anyone-puts-002049678.html%29" target="_blank" rel="noopener">https://www.yahoo.com/news/pence-trumps-indictment-anyone-puts-002049678.html)</a>. That means 2B treats all shares from yahoo.com the same, while 2B looks at each story separately.</p>
<p>If you&rsquo;re like me, when you think of political news, you have in mind domains like FoxNews.com or MSNBC.com, where it&rsquo;s likely that the website itself has a distinct partisan flavor.</p>
<p>But YouTube.com and Twitter.com both appear in the &ldquo;Top 100 Domains by Views&rdquo; in the study&rsquo;s SM, which obviously host a ton of both far left and far right or &ldquo;mixed&rdquo; content. And indeed, Figure S10 below shows that there are an array of domains that host some far right content and some far left content.</p>
<p>















<figure  id="figure-some-domains-host-some-far-right-content-urls-and-some-far-left-content">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/BailonFigS10.jpeg" alt="Figure S10 from González-Bailón et al 2023: Some domains host some far right content and some far left content." loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Some domains host some far right content (URLs) and some far left content.
    </figcaption></figure>
</p>
<!-- There's also just something about content that makes an argument that we seem to want to share, as suggested by analysis in my [dissertation](https://www.dropbox.com/s/zfw1d9j60hqjil7/sudiss.pdf?raw=true), which shows that NYT editorials are more likely than content from other sections to be shared (via email). Consider two OpEds at the NYT---one by conservative columnist Bret Stevens, the other by well-known liberal Nicholas Kristof. The former is going to be shared more by conservatives, the latter more by liberals.  -->
<p>But even if we&rsquo;re talking about NYTimes.com it&rsquo;s not hard to see that for example, conservatives might be more likely to share conservative Op Eds from Bret Stevens, while liberals may be more likely to share Op Eds from Nicholas Kristof.</p>
<p>If you aggregate your analysis to the domain level, you&rsquo;ll miss this aspect of media polarization.</p>
<h3 id="domains-or-urls">Domains or URLs</h3>
<p>So which is right? <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a> suggests that we should prefer the URL-level analysis. Here&rsquo;s the passage in the discussion section, which describes why analyzing media polarization at the level of the domain is problematic:</p>
<p>&ldquo;As a result of social curation, exposure to URLs is systematically more segregated than exposure to domains&hellip; <em>A focus on domains rather than URLs will likely understate, perhaps substantially, the degree of segregation in news consumption online.</em>&rdquo; (Emphasis added)</p>
<p>What&rsquo;s more, past work (co-authored by one of the lead authors) shows that <a href="https://osf.io/vbwer" target="_blank" rel="noopener">domain-level analysis can indeed mask “curation bubbles”</a> in which &ldquo;specific stories attract different partisan audiences than is typical for the outlets that produced them.&rdquo;</p>
<p>You can see this in the data clear as day&mdash;let&rsquo;s go back to Figure 2A, which shows a massive increase in estimated segregation when using URLs rather than domains:</p>
<p>















<figure  id="figure-figure-2a-shows-much-higher-levels-of-audience-segregation-when-you-look-at-the-url-level-rather-than-the-domain-level">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/BailonFig2.jpg" alt="Figure 2 from González-Bailón et al 2023: There are much higher levels of audience segregation when you look at the URL level rather than the domain level" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure 2A shows much higher levels of audience segregation when you look at the URL level rather than the domain level
    </figcaption></figure>
</p>
<p>Returning to Figures 2B and 2C, it seems that the potential audience at domain level is <em>artificially less segregated</em>, due to the aggregation at the level of the domain.</p>
<h3 id="what-explains-the-filter-bubble-discrepency">What explains the &lsquo;Filter Bubble discrepency&rsquo;?</h3>
<p>One possibility is that posts linking to content from &ldquo;mixed&rdquo; domains like YouTube, Reddit, Twitter, Yahoo, etc. do not score as well in feed-ranking. It&rsquo;s possible that partisan content on these domains is more likely to be downranked as misinformation or spam, or maybe Facebook-native videos (which render faster/better) have an edge over YouTube, or perhaps there are domain-level features in feed ranking, or maybe there is some other reason that content from &rsquo;non-mixed&rsquo; domains just performs better in the rather complex recommendation system that powers Newsfeed ranking.</p>
<p>Regardless, that would explain the results in Figure 2&mdash;making the potential audience look artificially broader than the actual audience, when you analyze content at the domain level.</p>
<h3 id="what-about-the-reverse-chron-experiment">What about the Reverse-Chron experiment?!</h3>
<p>Surely we can paint a fuller picture of the impact of algorithmic ranking on media polarization with that other excellent recent <em>Science</em> paper which looked at the <em>causal</em> effect of turning off Newsfeed ranking. Maybe we can cross-reference that paper and get a clearer picture of what&rsquo;s happening.</p>
<p><a href="https://www.science.org/doi/10.1126/science.abp9364" target="_blank" rel="noopener">Guess et al 2023</a> shows that Newsfeed induces proportionally <em>more</em> exposure cross-cutting sources but also more exposure to like-minded sources. It reduces exposure to moderate or mixed sources. Importantly, this is not just news that news sources link to, it&rsquo;s all content that everyone posts, including life updates, pictures, videos, etc.</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/GuessFig.jpg" alt="Figure 2 from Guess et al 2023: Compared to a reverse chronologically-ranked feed, FB&rsquo;s ranking system induces a proportionally more exposure to &ldquo;like-minded&rdquo; sources but also more to cross-cutting sources, defined at the level of the entity posting." loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>Ok, but what about political content? In the supplimentary materials, we see that when it comes to <em>political content</em>, Newsfeed ranking actually <em>decreases</em> exposure to political content from like-minded sources.</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/GuessChronScienceTabS20.jpg" alt="Figure S20 from Guess et al 2023: A reverse chronologically-ranked Newsfeed induces a proportionally less exposure to &ldquo;like-minded&rdquo; sources but also less to cross-cutting sources, defined at the level of the entity posting." loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>What about exposure to political content posted by cross-cutting sources? The SM doesn&rsquo;t provide that, but it does provide a paragraph noting that Newsfeed <em>decreased</em> exposure to political news from partisan sources relative to reverse-chron!</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/GuessChronScienceS3.3.jpg" alt="S3.3 in Guess et al 2023: A reverse chronologically-ranked Newsfeed induces a proportionally less exposure to &ldquo;like-minded&rdquo; sources but also less to cross-cutting sources, defined at the level of the entity posting." loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>Now a big caveat here is that it&rsquo;s clear from the main results that political content is not doing well in Newsfeed ranking. Note that there are <a href="https://www.wsj.com/articles/facebook-politics-controls-zuckerberg-meta-11672929976" target="_blank" rel="noopener">reports that the company decided to downrank political and news content in 2021</a>.</p>
<p>Regardless, the results in the SM are not at all suggestive of a filter bubble, at least during the 2020 election&mdash;the experimental results suggest that if anything feedranking is showing us <em>less</em> polarizing content than we would see with reverse-chron.</p>
<h3 id="how-fb-groups-impact-estimates-of-algorithmic-segregation">How FB Groups impact estimates of algorithmic segregation</h3>
<p>I sent a much earlier draft of this to <a href="https://www.asc.upenn.edu/people/faculty/sandra-gonzalez-bailon-phd" target="_blank" rel="noopener">Sandra González-Bailón</a> and <a href="https://cssh.northeastern.edu/faculty/david-lazer/" target="_blank" rel="noopener">David Lazer</a>, lead authors for <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a>. Sandra pointed me to Figure S14, which does show a slight increase in segregation post-ranking for URLs shared by users and pages, but shows the <em>opposite</em> for content shared in those often-contentious Facebook groups.</p>
<!-- People may be especially likely to come across "persons dissimilar to themselves, and with modes of thought and action unlike those with which they are familiar" [(Mill cited in Mutz and Mondak, 2006)](https://www.polisci.upenn.edu/sites/default/files/mutz_mondak_2006.pdf). And it seems likely based on the plot below that group posts are treated differently from page posts and friend posts in Facebook feedranking.  -->
<p>So it&rsquo;s really <em>not</em> that there&rsquo;s no difference at all pre- and post- ranking, just that the difference is on average zero once you include groups. Of course, the population of people who see content from groups and/or pages in Newsfeed may be unusual, and future work should dig into this variation.</p>
<p>I should also note that this small but real difference seems more or less consistent with what we <a href="https://www.science.org/doi/10.1126/science.aaa1160" target="_blank" rel="noopener">found in past work</a>, which only examined news shared by users (excluding pages and groups).</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/BailonFigS14.jpg" alt="Figure S14 from González-Bailón et al 2023: There is a modest filter bubble effect among users and pages, and a &ldquo;reverse filter bubble&rdquo; for content shared in groups." loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<h3 id="the-algorithm-and-the-most-politically-engaged">The algorithm and the most politically engaged</h3>
<p>There is also a hint of an increase in segregation post-ranking among the most politically engaged 10% of Facebook users. However, the paper notes that this trend &ldquo;is only clear for domain-level data,&rdquo; which we&rsquo;ve already established should not be used here. (Note that they define high political interest users as those in the &ldquo;top 10% of engagement&hellip; (comments, likes, reactions, reshares) with content classified as political on Facebook&hellip;)&rdquo;).</p>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/BailonFigS19.jpg" alt="Figure S19 shows a modest filter bubble effect among the most engaged users at the peak of the 2020 election." loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p>A similar pattern holds for the top 1% of users (Figure S23 in the SM).</p>
<h3 id="algorithmic-segregation-and-ideology">Algorithmic segregation and ideology</h3>
<p>Feed ranking seems to expose both conservatives and liberals to more liberal content. This is consistent with my priors that conservative content is more likely to violate policy and be taken down or subject to &ldquo;soft actioning&rdquo; (e.g., downranking) for borderline violations.</p>
<p>So now things get messy&mdash;should we really say liberals are in a filter bubble (and conservatives aren&rsquo;t) if misinformation is included in that calculation?</p>
<!-- exposure to cross cutting content was thought to [reduce political participation](https://www.jstor.org/stable/3088437). -->
<p>















<figure  id="figure-feedranking-exposes-you-to-slightly-more-liberal-content">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/BailonTabS8.jpeg" alt="Feedranking exposes you to slightly more liberal content, presumably due to misinformation actioning." loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Feedranking exposes you to slightly more liberal content.
    </figcaption></figure>
</p>
<p>We can see a similar pattern when we look at exposure to cross-cutting content, which is the measure our 2015 Science paper used. Conservatives see more liberal content in feed than their friends share.</p>
<p>















<figure  id="figure-replication-of-bakshy-et-al-2015">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/BailonFigS11.jpg" alt="Replication of Bakshy et al 2015, showing little effect of feed-ranking among content shared by friends. However, when including page and group content, feed-ranking plays a more important role&mdash;exposing liberals to proportionally less cross-cutting content and conservatives to comparatively more." loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Replication of Bakshy et al 2015
    </figcaption></figure>
</p>
<p>We can also see that things have changed a lot since we wrote our original Science piece in 2015. Liberals seem to see <em>far</em> more cross-cutting content, conservatives less.</p>
<!-- What about how this compares to others ways we get media on the internet? The evidence is not great here, but [Flaxman et al 2016](https://academic.oup.com/poq/article/80/S1/298/2223402) show that ideological segregation is higher for search than for social media websites, but lower for news aggregators and direct navigation to news websites.  -->
<h3 id="brevity-is-a-double-edged-sword">Brevity is a double-edged sword</h3>
<p>Science gives authors only limited space and it would have been difficult to dig into everything I&rsquo;ve written about in 2 pages. I also know better than almost anyone just how much work went into these papers (I would bet thousands of hours for each of several authors), and how difficult it can be explain everything perfectly when you&rsquo;re pulling off such a big lift. I should also point out that these papers are very nuanced, well-caveated, and careful not to overstate their results regarding the filter bubble or algorithmic polarization.</p>
<p>Still, I do wish this work had squarely focused on URL-level analyses.</p>
<h3 id="what-this-means-for-other-studies">What this means for other studies</h3>
<p>This also means that past estimates of ideological segregation based domain-level analysis probably <em>understate</em> media polarization in a big way. This includes those based on <a href="https://journalqd.org/article/view/2586/2683" target="_blank" rel="noopener">Facebook data</a>, <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/ajps.12589" target="_blank" rel="noopener">browser data</a>, on data describing various <a href="https://academic.oup.com/poq/article/80/S1/298/2223402" target="_blank" rel="noopener">platforms</a>) or simply websites across the <a href="https://web.stanford.edu/~gentzkow/research/echo_chambers.pdf" target="_blank" rel="noopener">internet</a>. I have said this for a long time but I did not think the magnitude was as strong as shown in <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a>.</p>
<h3 id="so-is-facebook-polarizing">So, is Facebook polarizing?</h3>
<p>It&rsquo;s very hard to give a good answer to this question. In &ldquo;The Paradox of Minimal Effects,&rdquo; Stephen Ansolabehere points out that re-election depends overwhelmingly on whether the country is prosperous and at peace, not what happens with media politics. This is thought to be because people selectively consume media, which serves mainly to reinforce their beliefs; while at the same time, the sum total of people&rsquo;s private lived experiences correponds reasonably well to aggregated economic data.</p>
<p>There&rsquo;s an argument that social media exists somewhere in between the conventional media and one&rsquo;s lived experiences. And what about evidence? As Sean Westwood and I have shown, partisan selectivity is far less severe when you <a href="https://journals.sagepub.com/doi/10.1177/0093650212466406" target="_blank" rel="noopener">add a social element to news consumption</a>. What&rsquo;s more, field-experimental work I did shows that <a href="https://www.dropbox.com/s/nu39148ukbab34r/CH7brief.pdf?raw=true" target="_blank" rel="noopener">increasing the prominence of political news in Facebook&rsquo;s Newsfeed</a> shifted issue positions toward the majority of news encountered (left-leaning), particularly among political moderates.</p>
<p>Tom Cunningham recently wrote a nice <a href="https://tecunningham.github.io/posts/2023-07-27-meta-2020-elections-experiments.html#other-evidence-on-media-and-polarization" target="_blank" rel="noopener">summary of some of the evidence related to the question of whether any kind of media might increase affective polarization</a>, which we discussed at length.</p>
<p>The evidence suggests any effect is likely small. First, we see that while social media is a global phenomenon, affective polarization is not&mdash;the <a href="https://direct.mit.edu/rest/article-abstract/doi/10.1162/rest_a_01160/109262/Cross-Country-Trends-in-Affective-Polarization?redirectedFrom=fulltext" target="_blank" rel="noopener">UK, Japan, and Germany have seen affective depolarization</a>.</p>
<p>Second, perhaps the highest quality experimental study on this question I&rsquo;ve seen is <a href="https://osf.io/jrw26/" target="_blank" rel="noopener">Broockman and Kalla (2022)</a>, which finds that paying heavy Fox News viewers to watch CNN has generally depolarizing effects, though as Tom points out, finds null effects on traditional measures of affective polarization.</p>
<p>Third, Tom and I have also discussed an excellent experimental study attempting to shed light on this: &ldquo;<a href="https://www.aeaweb.org/articles?id=10.1257/aer.20190658" target="_blank" rel="noopener">Welfare Effects of Social Media</a>,&rdquo; which concludes that Facebook is likely polarizing. They find that &ldquo;deactivating Facebook for the four weeks before the 2018 US midterm election&hellip; makes people less informed, it also makes them less polarized by at least some measures, consistent with the concern that social media have played some role in the recent rise of polarization in the United States.&rdquo;</p>
<p>The study defines political polarization in an unusual way&mdash;including congenial media exposure&mdash;how much news you see from your own side&mdash;in its polarization index. Most political scientists would consider congenial media exposure as <em>the thing that might cause polarization</em>, but not an aspect of polarization in and of itself.</p>
<p>















<figure  id="figure-allcott-et-al-2020-figure-3-demonstrates-the-biggest-effect-is-on-a-measure-of-media-exposure">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/AlcottetalFigure3.jpg" alt="Allcott et al 2020 Figure 3" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Allcott et al 2020 Figure 3 demonstrates the biggest effect is on a measure of media exposure
    </figcaption></figure>
</p>
<p>They do explain that their effects on affective polarization are not significant and they don&rsquo;t try to hide what&rsquo;s going into the measure. But you have to read beyond the abstract and the media headlines to really understand this point.</p>
<!-- They make the following claim in a footnote: "Online Appendix Table A16 shows that the effect on the political polarization index is *robust to excluding each of the seven individual component variables in turn*, although the point estimate moves toward zero and the unadjusted p-value rises to 0.09 when omitting congenial news exposure."  -->
<p>Notably, in a robustness test in the appendix, the effect on the polarization loses statistical significance when you exclude this variable.</p>
<p>















<figure  id="figure-allcott-et-al-2020-figure-a16-shows-that-the-effect-on-polarization-is-not-significant-at-p005-if-you-exclude-congenial-media-exposure">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/AlcottetalFigureA16.jpg" alt="Allcott et al 2020 Figure A16" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Allcott et al 2020 Figure A16 shows that the effect on polarization is not significant at P&lt;0.05 if you exclude congenial media exposure.
    </figcaption></figure>
</p>
<p>That means the folks who didn&rsquo;t deactivate Facebook had higher levels of political knowledge and higher levels of issue polarization. This makes sense because if a person doesn&rsquo;t know where the parties stand on an issue, she is less likely to be sure about where she ought to stand.</p>
<h3 id="implications-for-how-this-was-publicized">Implications for how this was publicized</h3>
<p>All of this is relevant in light of the controversial Science Cover, which suggests Facebook&rsquo;s <em>algorithms</em> are &ldquo;Wired to Split&rdquo; us. It may be true, but the evidence across all 4 <em>Science</em> and <em>Nature</em> papers is not decisive on this question.</p>
<p>None of the experiments published so far show an impact on affective or ideological polarization. What&rsquo;s more, the proper URL-level analyses in <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a> show only a modest &lsquo;Filter Bubble&rsquo; for certain subsets of the data, and when it comes to political news, and the reverse-chronological feed ranking experiment shows Newsfeed ranking feeds us <em>less</em> polarized political content than would see in a reverse-chron Newsfeed.</p>
<p>Of course, the spin from the Meta Comms team that these <a href="https://www.wsj.com/articles/does-facebook-polarize-users-meta-disagrees-with-partners-over-research-conclusions-24fde67a" target="_blank" rel="noopener">results are exculpretory</a> is also highly problematic. This claim is not only wrong but amatuerish and self-defeating from a strategic perspective, and I was surprised to read about it.</p>
<p>For all the amazing work done to produce the experimental results, the data are too noisy to detect small but potentially compounding effects on polarization as suggested in <a href="https://statmodeling.stat.columbia.edu/author/dean/" target="_blank" rel="noopener">a post-publication review from Dean Eckles</a> and <a href="https://tecunningham.github.io/posts/2023-07-27-meta-2020-elections-experiments.html" target="_blank" rel="noopener">Tom Cunningham</a>.</p>
<p>What&rsquo;s more, even the excellent work done here in <a href="https://www.science.org/doi/full/10.1126/science.ade7138" target="_blank" rel="noopener">González-Bailón et al 2023</a> does not speak to the question of effects on polarization that other key recommender systems at Facebook may have: the People You May Know (PYMK) algorithm, which facilitates network connections on the website, along with the Pages You Might Like (PYML) and Groups You Might Like (GYML). The authors make a similar point in the Supplementary Materials, S3.2&mdash;pointing out that inventory, or the &ldquo;potential audience,&rdquo; &ldquo;results from another curation process determining the structure and composition of the Facebook graph, which itself results from social and algorithmic dynamics.&rdquo;</p>
<p>This means that we should <em>not</em> necessarily conclude that exposure is all about individual choices and not algorithms based on the sum total of evidence we have (a point I should have better emphasized <a href="https://solomonmg.github.io/pdf/Science-2015-Bakshy-1130-2.pdf" target="_blank" rel="noopener">in past work</a>)&mdash;algorithms may play an important role and as usual, more research is needed.</p>
<p>It would seem to me that both Science and Meta Comms are both going beyond the data here.</p>
<p>















<figure  id="figure-wired-to-split">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/img/ScienceCoverWiredtoSplit.jpeg" alt="The Science Cover suggests Facebook&rsquo;s algorithms are &ldquo;Wired to Split&rdquo; us." loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Wired to Split
    </figcaption></figure>
</p>
<h3 id="disclosures">Disclosures</h3>
<p>As noted above, from 2018-2020, I was tech lead for Social Science One, which gave external researchers <em>direct</em> access to data (the <a href="/pdf/Facebook_DP_URLs_Dataset.pdf">&lsquo;Condor&rsquo; URLs data set</a>) via differential privacy. However, that project has not yielded much research output for a number of organizational and operational reasons, including the fact that differential privacy is not yet suitable for such a complex project.</p>
<p>While at Facebook, I personally advocated (with Annie Franco) for the collaboration model used in the Election 2020 project, wherein external researchers would collaborate with Facebook researchers. That model would have to shield the research from any interference from Facebook&rsquo;s Communications and Policy arm, which would violate scientific ethics. It would involve pre-registration, not merely to ensure scientific rigor but to protect against conflicts of interest and selective reporting of results. However, I left Facebook in January of 2020 and have not been deeply involved in the project since.</p>
<p>I recently left Twitter (requesting to be in the first rounds of layoffs after Elon Musk took over) and started a job at NYU&rsquo;s CSMaP lab when my employment with Twitter ended. There are authors who are affiliated with my lab on the paper, including one of the PIs, Josh Tucker. My graduate school Advisor, Shanto Iyengar is also on the paper, and I consider the majority of the authors to be my colleagues and friends.</p>
<p>See also my <a href="/disclosures/">disclosures page</a>.</p>
<!-- I do wish the samples and timeframes for the ranking experiments were bigger so we could understand potentially smaller effects, which may be very important.  -->
    </div>

    







<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fsolmessing.netlify.app%2Fpost%2Fthoughts-on-election-2020%2F&amp;text=Disaggregating&#43;%27Ideological&#43;Segregation%27" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fsolmessing.netlify.app%2Fpost%2Fthoughts-on-election-2020%2F&amp;t=Disaggregating&#43;%27Ideological&#43;Segregation%27" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=Disaggregating%20%27Ideological%20Segregation%27&amp;body=https%3A%2F%2Fsolmessing.netlify.app%2Fpost%2Fthoughts-on-election-2020%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fsolmessing.netlify.app%2Fpost%2Fthoughts-on-election-2020%2F&amp;title=Disaggregating&#43;%27Ideological&#43;Segregation%27" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=Disaggregating&#43;%27Ideological&#43;Segregation%27%20https%3A%2F%2Fsolmessing.netlify.app%2Fpost%2Fthoughts-on-election-2020%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fsolmessing.netlify.app%2Fpost%2Fthoughts-on-election-2020%2F&amp;title=Disaggregating&#43;%27Ideological&#43;Segregation%27" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    




  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    ©2023 Sol Messing. This work is licensed under XX
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> — the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.d613345003d21781ec611233eea95b85.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.b95a7e109243f29d04930ae8cb49a756.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.69fc52a6dc16aaf1a452cfbb36466dac.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js" type="module"></script>


















</body>
</html>
